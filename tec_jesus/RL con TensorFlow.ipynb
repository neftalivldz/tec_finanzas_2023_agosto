{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "\n",
    "\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from pandas_datareader import data as pdr\n",
    "import yfinance as yf\n",
    "yf.pdr_override()\n",
    "\n",
    "\n",
    "from tqdm import tqdm_notebook, tqdm\n",
    "from collections import deque\n",
    "\n",
    "#Warning ignore\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AI_Trader():\n",
    "  \n",
    "  def __init__(self, state_size, action_space=3, model_name=\"AITrader\"): #Stay, Buy, Sell\n",
    "    \n",
    "    self.state_size = state_size\n",
    "    self.action_space = action_space\n",
    "    self.memory = deque(maxlen=2000)\n",
    "    self.inventory = []\n",
    "    self.model_name = model_name\n",
    "    \n",
    "    # Define hyperparamaters\n",
    "    self.gamma = 0.95\n",
    "    self.epsilon = 1.0\n",
    "    self.epsilon_final = 0.01\n",
    "    self.epsilon_decay = 0.995\n",
    "        \n",
    "    # Call a function  to build a model trought this class constructor\n",
    "    # More parameters could be ustilized to programaticaly define network size (layers and neurons)\n",
    "    self.model = self.model_builder()\n",
    "    \n",
    "    \n",
    "  def model_builder(self):\n",
    "    metrics = [tf.keras.metrics.BinaryAccuracy(),tf.keras.metrics.FalseNegatives(), tf.keras.metrics.Accuracy()]\n",
    "    model = tf.keras.models.Sequential()    \n",
    "    model.add(tf.keras.layers.Dense(units=32, activation='relu', input_dim=self.state_size))    \n",
    "    model.add(tf.keras.layers.Dense(units=64, activation='relu'))    \n",
    "    model.add(tf.keras.layers.Dense(units=128, activation='relu'))    \n",
    "    model.add(tf.keras.layers.Dense(units=self.action_space, activation='linear'))    \n",
    "    model.compile(loss='mse', optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
    "              metrics=metrics)\n",
    "    return model\n",
    "  \n",
    "  \n",
    "  \n",
    "  \n",
    "  # Trade function that takes state as an input and returns an action \n",
    "  # to perform in perticular state \n",
    "  def trade(self, state):\n",
    "    \n",
    "    # Should we perform a renadom generated action or action defined in model?\n",
    "    \n",
    "    # If value from our random generator is smaller or equal to our epsilon \n",
    "    #     then we will retun a random action from action_space [0-3)\n",
    "    if random.random() <= self.epsilon:\n",
    "      return random.randrange(self.action_space)\n",
    "    \n",
    "    # If our random is greater than epsilon then we will use model to perform action\n",
    "    actions = self.model.predict(state)\n",
    "    # return only a one number defining an action (#Stay - 0 , Buy - 1, Sell - 2) \n",
    "    #    that has maximum probability\n",
    "    return np.argmax(actions[0])\n",
    "  \n",
    "  \n",
    "  \n",
    "  def batch_train(self, batch_size):\n",
    "    \n",
    "    batch = []\n",
    "    \n",
    "    # Iterrate in momory, we do not want to randolmy select data as we are dealing with \n",
    "    #    time constraint data. We will always sample from the end of memory size of bath\n",
    "    for i in range(len(self.memory) - batch_size + 1, len(self.memory)):\n",
    "      # insert data from memory to batch      \n",
    "      batch.append(self.memory[i])\n",
    "    \n",
    "    \n",
    "    # Iterate trought batch of data and train the model for each sample from batch\n",
    "    # Order of variables in for loop is important\n",
    "    for state, action, reward, next_state, done in batch:\n",
    "      # Reward if agent is in terminal state\n",
    "      reward = reward\n",
    "      # Check that agent is not in terminal state\n",
    "      # If not in terminal state calculate reward for actions that could be played\n",
    "      if not done:\n",
    "        # Discounted total reward:\n",
    "        reward = reward + self.gamma * np.amax(self.model.predict(next_state)[0])        \n",
    "      # Target variable that is predicted by the model (action)\n",
    "      target = self.model.predict(state)\n",
    "      target[0][action] = reward\n",
    "      \n",
    "      self.model.fit(state, target, epochs=1, verbose=0)\n",
    "\n",
    "      \n",
    "    # We will decrease epsilon parameter that is 1 as defined in __init__  so\n",
    "    #    so we can stop performing random actions at some point\n",
    "    if self.epsilon > self.epsilon_final:\n",
    "      self.epsilon *= self.epsilon_decay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "  return 1 / (1 + np.exp(-x))\n",
    "\n",
    "  \n",
    "def stocks_price_format(n):\n",
    "  if n < 0:\n",
    "    return \"- $ {0:2f}\".format(abs(n))\n",
    "  else:\n",
    "    return \"$ {0:2f}\".format(abs(n))\n",
    "\n",
    "\n",
    "def dataset_loader(stock_name):\n",
    "  \n",
    "  #Use pandas data reader for reading stock data from warious sources like \"yahoo\", \"google\"\n",
    "  dataset = pdr.get_data_yahoo(stock_name, start=\"2017-01-01\", end=\"2024-01-01\")\n",
    "   \n",
    "  # Get start and end time to variables from dataset\n",
    "  start_date = str(dataset.index[0]).split()[0]\n",
    "  end_date = str(dataset.index[-1]).split()[0]\n",
    "  \n",
    "  # Model will use \"Close\" column for training \n",
    "  close = dataset['Close']\n",
    "\n",
    "  return close\n",
    "\n",
    "# Data -> dataset to predict from, gathered by data:loader()\n",
    "# Timestep -> Day in the dataset that we want to predict for [0:datalength]\n",
    "# window_suze -> how many days in past we want to use to predict current status[1:datalength]\n",
    "#         Try different setup to see what creates best fit\n",
    "def state_creator(data, timestep, window_size):\n",
    "  \n",
    "  # starting day of our state\n",
    "  starting_id = timestep - window_size + 1\n",
    "  \n",
    "  if starting_id >= 0:\n",
    "    windowed_data = data[starting_id:timestep+1]\n",
    "  else:\n",
    "    # Replicate member (data[0]) needed times\n",
    "    windowed_data = - starting_id * [data[0]] + list(data[0:timestep+1])\n",
    "    \n",
    "  state = []\n",
    "  # Iterate trough whole windowed_data minus current state (-1)\n",
    "  for i in range(window_size - 1):\n",
    "    # Normalize the difference from current day and the next day\n",
    "    # Because the prices can be very different and we want them on same scale\n",
    "    state.append(sigmoid(windowed_data[i+1] - windowed_data[i]))\n",
    "    \n",
    "  return np.array([state])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def state_indicador_creator(data, timestep, window_size):\n",
    "\n",
    "    state = []\n",
    "    if timestep == 0:\n",
    "        state.append(sigmoid(data.iloc[0:1, :window_size].values - data.iloc[0:1, :window_size].values))\n",
    "    else:\n",
    "        state.append(sigmoid(data.iloc[timestep:timestep + 1, :window_size].values - data.iloc[timestep -1 :timestep, :window_size].values))\n",
    "\n",
    "    return np.reshape(state,(1,window_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed\n"
     ]
    }
   ],
   "source": [
    "## Carga los datos utilizados para los indicadores\n",
    "data = pd.read_parquet('resultadoIndicadores.parquet')\n",
    "data = data.drop(['EMA_5','EMA_63', 'EMA_63', 'WMA_63', 'MINUS_DM','PLUS_DI', 'AD', 'WMA_5'], axis=1)\n",
    "\n",
    "# Tage data for Apple ------------------------\n",
    "stock_name = \"AAPL\"\n",
    "data2 = dataset_loader(stock_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Series' object has no attribute 'columns'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_1760\\3903678743.py\u001b[0m in \u001b[0;36m?\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdata2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\Users\\jesiq\\anaconda3\\envs\\talib\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m   6200\u001b[0m             \u001b[1;32mand\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_accessors\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6201\u001b[0m             \u001b[1;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_info_axis\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_can_hold_identifiers_and_holds_name\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6202\u001b[0m         ):\n\u001b[0;32m   6203\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 6204\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m: 'Series' object has no attribute 'columns'"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "window_size = 10\n",
    "episodes = 1000 # same as epoch\n",
    "\n",
    "batch_size = 32\n",
    "data_samples = len(data) - 1 # discard last value, that we will predict on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 32)                352       \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 64)                2112      \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 128)               8320      \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 3)                 387       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 11171 (43.64 KB)\n",
      "Trainable params: 11171 (43.64 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "trader = AI_Trader(window_size)\n",
    "trader.model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 9)"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state_creator(data2, 0, 10).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 9)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state_indicador_creator(data, timestep=0, window_size=9).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|█▊        | 9/50 [00:00<00:00, 1499.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AI Trader bought:  SMA_5       157.407278\n",
      "SMA_21      146.413159\n",
      "SMA_63      159.001651\n",
      "EMA_21      152.134367\n",
      "WMA_21      150.466651\n",
      "middle      152.139257\n",
      "SAR         144.248832\n",
      "PLUS_DM      23.993968\n",
      "MINUS_DI     11.736027\n",
      "ADX          22.642737\n",
      "Name: 2020-04-09 00:00:00, dtype: float64\n",
      "AI Trader bought:  SMA_5       159.669067\n",
      "SMA_21      147.632669\n",
      "SMA_63      159.072493\n",
      "EMA_21      152.872328\n",
      "WMA_21      151.724722\n",
      "middle      152.911893\n",
      "SAR         146.308925\n",
      "PLUS_DM      21.594571\n",
      "MINUS_DI     11.984357\n",
      "ADX          22.849732\n",
      "Name: 2020-04-13 00:00:00, dtype: float64\n",
      "AI Trader bought:  SMA_5       161.301508\n",
      "SMA_21      148.318269\n",
      "SMA_63      159.239471\n",
      "EMA_21      154.264094\n",
      "WMA_21      153.592821\n",
      "middle      154.366167\n",
      "SAR         148.204211\n",
      "PLUS_DM      27.615107\n",
      "MINUS_DI     10.902617\n",
      "ADX          23.879020\n",
      "Name: 2020-04-14 00:00:00, dtype: float64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "operands could not be broadcast together with shapes (0,) (10,) ",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\jesiq\\github\\Material_tec\\Codigos\\RL con TensorFlow.ipynb Cell 10\u001b[0m line \u001b[0;36m2\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/jesiq/github/Material_tec/Codigos/RL%20con%20TensorFlow.ipynb#Y102sZmlsZQ%3D%3D?line=24'>25</a>\u001b[0m   \u001b[39m# If we gain money (current price - buy price) we have reward \u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/jesiq/github/Material_tec/Codigos/RL%20con%20TensorFlow.ipynb#Y102sZmlsZQ%3D%3D?line=25'>26</a>\u001b[0m   \u001b[39m#    if we lost money then reward is 0\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/jesiq/github/Material_tec/Codigos/RL%20con%20TensorFlow.ipynb#Y102sZmlsZQ%3D%3D?line=26'>27</a>\u001b[0m   reward \u001b[39m=\u001b[39m data\u001b[39m.\u001b[39miloc[t] \u001b[39m-\u001b[39m buy_price\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/jesiq/github/Material_tec/Codigos/RL%20con%20TensorFlow.ipynb#Y102sZmlsZQ%3D%3D?line=27'>28</a>\u001b[0m   total_profit \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m data\u001b[39m.\u001b[39miloc[t] \u001b[39m-\u001b[39m buy_price\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/jesiq/github/Material_tec/Codigos/RL%20con%20TensorFlow.ipynb#Y102sZmlsZQ%3D%3D?line=28'>29</a>\u001b[0m   \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mAI Trader sold: \u001b[39m\u001b[39m\"\u001b[39m, data\u001b[39m.\u001b[39miloc[t]), \u001b[39m\"\u001b[39m\u001b[39m Profit: \u001b[39m\u001b[39m\"\u001b[39m \u001b[39m+\u001b[39m data\u001b[39m.\u001b[39miloc[t] \u001b[39m-\u001b[39m buy_price \n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/jesiq/github/Material_tec/Codigos/RL%20con%20TensorFlow.ipynb#Y102sZmlsZQ%3D%3D?line=30'>31</a>\u001b[0m \u001b[39m# if t is last sample in our dateset we are done\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/jesiq/github/Material_tec/Codigos/RL%20con%20TensorFlow.ipynb#Y102sZmlsZQ%3D%3D?line=31'>32</a>\u001b[0m \u001b[39m#     we do not have any steps to perform in current episode\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\jesiq\\anaconda3\\envs\\talib\\lib\\site-packages\\pandas\\core\\ops\\common.py:76\u001b[0m, in \u001b[0;36m_unpack_zerodim_and_defer.<locals>.new_method\u001b[1;34m(self, other)\u001b[0m\n\u001b[0;32m     72\u001b[0m             \u001b[39mreturn\u001b[39;00m \u001b[39mNotImplemented\u001b[39m\n\u001b[0;32m     74\u001b[0m other \u001b[39m=\u001b[39m item_from_zerodim(other)\n\u001b[1;32m---> 76\u001b[0m \u001b[39mreturn\u001b[39;00m method(\u001b[39mself\u001b[39;49m, other)\n",
      "File \u001b[1;32mc:\\Users\\jesiq\\anaconda3\\envs\\talib\\lib\\site-packages\\pandas\\core\\arraylike.py:190\u001b[0m, in \u001b[0;36mOpsMixin.__radd__\u001b[1;34m(self, other)\u001b[0m\n\u001b[0;32m    188\u001b[0m \u001b[39m@unpack_zerodim_and_defer\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39m__radd__\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    189\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__radd__\u001b[39m(\u001b[39mself\u001b[39m, other):\n\u001b[1;32m--> 190\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_arith_method(other, roperator\u001b[39m.\u001b[39;49mradd)\n",
      "File \u001b[1;32mc:\\Users\\jesiq\\anaconda3\\envs\\talib\\lib\\site-packages\\pandas\\core\\series.py:5815\u001b[0m, in \u001b[0;36mSeries._arith_method\u001b[1;34m(self, other, op)\u001b[0m\n\u001b[0;32m   5813\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_arith_method\u001b[39m(\u001b[39mself\u001b[39m, other, op):\n\u001b[0;32m   5814\u001b[0m     \u001b[39mself\u001b[39m, other \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_align_for_op(other)\n\u001b[1;32m-> 5815\u001b[0m     \u001b[39mreturn\u001b[39;00m base\u001b[39m.\u001b[39;49mIndexOpsMixin\u001b[39m.\u001b[39;49m_arith_method(\u001b[39mself\u001b[39;49m, other, op)\n",
      "File \u001b[1;32mc:\\Users\\jesiq\\anaconda3\\envs\\talib\\lib\\site-packages\\pandas\\core\\base.py:1381\u001b[0m, in \u001b[0;36mIndexOpsMixin._arith_method\u001b[1;34m(self, other, op)\u001b[0m\n\u001b[0;32m   1378\u001b[0m     rvalues \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39marange(rvalues\u001b[39m.\u001b[39mstart, rvalues\u001b[39m.\u001b[39mstop, rvalues\u001b[39m.\u001b[39mstep)\n\u001b[0;32m   1380\u001b[0m \u001b[39mwith\u001b[39;00m np\u001b[39m.\u001b[39merrstate(\u001b[39mall\u001b[39m\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mignore\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[1;32m-> 1381\u001b[0m     result \u001b[39m=\u001b[39m ops\u001b[39m.\u001b[39;49marithmetic_op(lvalues, rvalues, op)\n\u001b[0;32m   1383\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_construct_result(result, name\u001b[39m=\u001b[39mres_name)\n",
      "File \u001b[1;32mc:\\Users\\jesiq\\anaconda3\\envs\\talib\\lib\\site-packages\\pandas\\core\\ops\\array_ops.py:285\u001b[0m, in \u001b[0;36marithmetic_op\u001b[1;34m(left, right, op)\u001b[0m\n\u001b[0;32m    281\u001b[0m     _bool_arith_check(op, left, right)  \u001b[39m# type: ignore[arg-type]\u001b[39;00m\n\u001b[0;32m    283\u001b[0m     \u001b[39m# error: Argument 1 to \"_na_arithmetic_op\" has incompatible type\u001b[39;00m\n\u001b[0;32m    284\u001b[0m     \u001b[39m# \"Union[ExtensionArray, ndarray[Any, Any]]\"; expected \"ndarray[Any, Any]\"\u001b[39;00m\n\u001b[1;32m--> 285\u001b[0m     res_values \u001b[39m=\u001b[39m _na_arithmetic_op(left, right, op)  \u001b[39m# type: ignore[arg-type]\u001b[39;00m\n\u001b[0;32m    287\u001b[0m \u001b[39mreturn\u001b[39;00m res_values\n",
      "File \u001b[1;32mc:\\Users\\jesiq\\anaconda3\\envs\\talib\\lib\\site-packages\\pandas\\core\\ops\\array_ops.py:220\u001b[0m, in \u001b[0;36m_na_arithmetic_op\u001b[1;34m(left, right, op, is_cmp)\u001b[0m\n\u001b[0;32m    217\u001b[0m     func \u001b[39m=\u001b[39m partial(expressions\u001b[39m.\u001b[39mevaluate, op)\n\u001b[0;32m    219\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 220\u001b[0m     result \u001b[39m=\u001b[39m func(left, right)\n\u001b[0;32m    221\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mTypeError\u001b[39;00m:\n\u001b[0;32m    222\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m is_cmp \u001b[39mand\u001b[39;00m (\n\u001b[0;32m    223\u001b[0m         left\u001b[39m.\u001b[39mdtype \u001b[39m==\u001b[39m \u001b[39mobject\u001b[39m \u001b[39mor\u001b[39;00m \u001b[39mgetattr\u001b[39m(right, \u001b[39m\"\u001b[39m\u001b[39mdtype\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m) \u001b[39m==\u001b[39m \u001b[39mobject\u001b[39m\n\u001b[0;32m    224\u001b[0m     ):\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    227\u001b[0m         \u001b[39m# Don't do this for comparisons, as that will handle complex numbers\u001b[39;00m\n\u001b[0;32m    228\u001b[0m         \u001b[39m#  incorrectly, see GH#32047\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\jesiq\\anaconda3\\envs\\talib\\lib\\site-packages\\pandas\\core\\computation\\expressions.py:242\u001b[0m, in \u001b[0;36mevaluate\u001b[1;34m(op, a, b, use_numexpr)\u001b[0m\n\u001b[0;32m    239\u001b[0m \u001b[39mif\u001b[39;00m op_str \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    240\u001b[0m     \u001b[39mif\u001b[39;00m use_numexpr:\n\u001b[0;32m    241\u001b[0m         \u001b[39m# error: \"None\" not callable\u001b[39;00m\n\u001b[1;32m--> 242\u001b[0m         \u001b[39mreturn\u001b[39;00m _evaluate(op, op_str, a, b)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m    243\u001b[0m \u001b[39mreturn\u001b[39;00m _evaluate_standard(op, op_str, a, b)\n",
      "File \u001b[1;32mc:\\Users\\jesiq\\anaconda3\\envs\\talib\\lib\\site-packages\\pandas\\core\\computation\\expressions.py:73\u001b[0m, in \u001b[0;36m_evaluate_standard\u001b[1;34m(op, op_str, a, b)\u001b[0m\n\u001b[0;32m     71\u001b[0m \u001b[39mif\u001b[39;00m _TEST_MODE:\n\u001b[0;32m     72\u001b[0m     _store_test_result(\u001b[39mFalse\u001b[39;00m)\n\u001b[1;32m---> 73\u001b[0m \u001b[39mreturn\u001b[39;00m op(a, b)\n",
      "File \u001b[1;32mc:\\Users\\jesiq\\anaconda3\\envs\\talib\\lib\\site-packages\\pandas\\core\\roperator.py:11\u001b[0m, in \u001b[0;36mradd\u001b[1;34m(left, right)\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mradd\u001b[39m(left, right):\n\u001b[1;32m---> 11\u001b[0m     \u001b[39mreturn\u001b[39;00m right \u001b[39m+\u001b[39;49m left\n",
      "\u001b[1;31mValueError\u001b[0m: operands could not be broadcast together with shapes (0,) (10,) "
     ]
    }
   ],
   "source": [
    "episode = 1\n",
    "state = state_indicador_creator(data, timestep=0, window_size=window_size)\n",
    "total_profit = []\n",
    "trader.inventory = []\n",
    "\n",
    "\n",
    "for t in tqdm(range(50)):\n",
    "    action = trader.trade(state)\n",
    "\n",
    "        # Use action to get to next state(t+)\n",
    "    next_state = state_indicador_creator(data=data, timestep=(t + 1), window_size=(9 + 1))\n",
    "    # As we did not calculate anything up to this point reward is 0\n",
    "    reward = 0\n",
    "    \n",
    "    if action == 1: #Buying\n",
    "      # Put buyed stock to inventory to trade with\n",
    "      trader.inventory.append(data.iloc[t])\n",
    "      print(\"AI Trader bought: \", data.iloc[t])\n",
    "      \n",
    "    # To sell we need to have something in inventory  \n",
    "    elif action == 2 and len(trader.inventory) > 0: #Selling\n",
    "      # Check buy price, pop removes first value from list\n",
    "      buy_price = trader.inventory.pop(0)\n",
    "      \n",
    "      # If we gain money (current price - buy price) we have reward \n",
    "      #    if we lost money then reward is 0\n",
    "      reward = data.iloc[t] - buy_price\n",
    "      total_profit += data.iloc[t] - buy_price\n",
    "      print(\"AI Trader sold: \", data.iloc[t]), \" Profit: \" + data.iloc[t] - buy_price \n",
    "      \n",
    "    # if t is last sample in our dateset we are done\n",
    "    #     we do not have any steps to perform in current episode\n",
    "    if t == data_samples - 1:\n",
    "      done = True\n",
    "    else:\n",
    "      done = False\n",
    "    \n",
    "    # Append all data to trader-agent memory, experience buffer\n",
    "    trader.memory.append((state, action, reward, next_state, done))\n",
    "    \n",
    "    # change state to next state, so we are done with an episode\n",
    "    state = next_state\n",
    "    \n",
    "    if done:\n",
    "      print(\"########################\")\n",
    "      print(\"TOTAL PROFIT: {}\".format(total_profit))\n",
    "      print(\"########################\")\n",
    "    \n",
    "    # Chekc if we have more information in our memory than batch size\n",
    "    if len(trader.memory) > batch_size:\n",
    "      trader.batch_train(batch_size)\n",
    "  \n",
    "  # Save the model every 10 episodes\n",
    "    if episode % 10 == 0:\n",
    "       trader.model.save(\"ai_trader_{}.h5\".format(episode))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SMA_5       7.164902\n",
       "SMA_21      0.210244\n",
       "SMA_63      0.195177\n",
       "EMA_21      3.626783\n",
       "WMA_21      5.824808\n",
       "middle      3.888752\n",
       "SAR         9.899292\n",
       "PLUS_DM     0.352776\n",
       "MINUS_DI   -5.263900\n",
       "ADX        -1.061055\n",
       "dtype: float64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.iloc[t] - buy_price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_profit += data.iloc[t] - buy_price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 153ms/step\n",
      "[[20.429379 21.630465 22.635977]]\n",
      "1/1 [==============================] - 0s 216ms/step\n",
      "[[20.429379 21.630465 22.635977]]\n"
     ]
    }
   ],
   "source": [
    "print(trader.model.predict(trader.memory[0][0]))\n",
    "\n",
    "print(trader.model.predict(trader.memory[1][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "deque([(array([[0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5]]),\n",
       "        1,\n",
       "        0,\n",
       "        array([[0.5       , 0.5       , 0.5       , 0.5       , 0.5       ,\n",
       "                0.5       , 0.5       , 0.5       , 0.5       , 0.79248934]]),\n",
       "        False),\n",
       "       (array([[0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5]]),\n",
       "        2,\n",
       "        0,\n",
       "        array([[0.5       , 0.5       , 0.5       , 0.5       , 0.5       ,\n",
       "                0.5       , 0.5       , 0.5       , 0.5       , 0.79248934]]),\n",
       "        False),\n",
       "       (array([[0.5       , 0.5       , 0.5       , 0.5       , 0.5       ,\n",
       "                0.5       , 0.5       , 0.5       , 0.5       , 0.79248934]]),\n",
       "        1,\n",
       "        0,\n",
       "        array([[0.5       , 0.5       , 0.5       , 0.5       , 0.5       ,\n",
       "                0.5       , 0.5       , 0.5       , 0.79248934, 0.45511914]]),\n",
       "        False),\n",
       "       (array([[0.5       , 0.5       , 0.5       , 0.5       , 0.5       ,\n",
       "                0.5       , 0.5       , 0.5       , 0.79248934, 0.45511914]]),\n",
       "        0,\n",
       "        0,\n",
       "        array([[0.5       , 0.5       , 0.5       , 0.5       , 0.5       ,\n",
       "                0.5       , 0.5       , 0.79248934, 0.45511914, 0.69211224]]),\n",
       "        False),\n",
       "       (array([[0.5       , 0.5       , 0.5       , 0.5       , 0.5       ,\n",
       "                0.5       , 0.5       , 0.79248934, 0.45511914, 0.69211224]]),\n",
       "        2,\n",
       "        0.6300048828125,\n",
       "        array([[0.5       , 0.5       , 0.5       , 0.5       , 0.5       ,\n",
       "                0.5       , 0.79248934, 0.45511914, 0.69211224, 0.3208213 ]]),\n",
       "        False),\n",
       "       (array([[0.5       , 0.5       , 0.5       , 0.5       , 0.5       ,\n",
       "                0.5       , 0.79248934, 0.45511914, 0.69211224, 0.3208213 ]]),\n",
       "        1,\n",
       "        0,\n",
       "        array([[0.5       , 0.5       , 0.5       , 0.5       , 0.5       ,\n",
       "                0.79248934, 0.45511914, 0.69211224, 0.3208213 , 0.5       ]]),\n",
       "        False),\n",
       "       (array([[0.5       , 0.5       , 0.5       , 0.5       , 0.5       ,\n",
       "                0.79248934, 0.45511914, 0.69211224, 0.3208213 , 0.5       ]]),\n",
       "        2,\n",
       "        0.0,\n",
       "        array([[0.5       , 0.5       , 0.5       , 0.5       , 0.79248934,\n",
       "                0.45511914, 0.69211224, 0.3208213 , 0.5       , 0.65475332]]),\n",
       "        False),\n",
       "       (array([[0.5       , 0.5       , 0.5       , 0.5       , 0.79248934,\n",
       "                0.45511914, 0.69211224, 0.3208213 , 0.5       , 0.65475332]]),\n",
       "        1,\n",
       "        0,\n",
       "        array([[0.5       , 0.5       , 0.5       , 0.79248934, 0.45511914,\n",
       "                0.69211224, 0.3208213 , 0.5       , 0.65475332, 0.36123513]]),\n",
       "        False),\n",
       "       (array([[0.5       , 0.5       , 0.5       , 0.79248934, 0.45511914,\n",
       "                0.69211224, 0.3208213 , 0.5       , 0.65475332, 0.36123513]]),\n",
       "        2,\n",
       "        0,\n",
       "        array([[0.5       , 0.5       , 0.79248934, 0.45511914, 0.69211224,\n",
       "                0.3208213 , 0.5       , 0.65475332, 0.36123513, 0.62714877]]),\n",
       "        False),\n",
       "       (array([[0.5       , 0.5       , 0.79248934, 0.45511914, 0.69211224,\n",
       "                0.3208213 , 0.5       , 0.65475332, 0.36123513, 0.62714877]]),\n",
       "        1,\n",
       "        0,\n",
       "        array([[0.5       , 0.79248934, 0.45511914, 0.69211224, 0.3208213 ,\n",
       "                0.5       , 0.65475332, 0.36123513, 0.62714877, 0.31002487]]),\n",
       "        False),\n",
       "       (array([[0.5       , 0.79248934, 0.45511914, 0.69211224, 0.3208213 ,\n",
       "                0.5       , 0.65475332, 0.36123513, 0.62714877, 0.31002487]]),\n",
       "        2,\n",
       "        0,\n",
       "        array([[0.79248934, 0.45511914, 0.69211224, 0.3208213 , 0.5       ,\n",
       "                0.65475332, 0.36123513, 0.62714877, 0.31002487, 0.62245933]]),\n",
       "        False),\n",
       "       (array([[0.79248934, 0.45511914, 0.69211224, 0.3208213 , 0.5       ,\n",
       "                0.65475332, 0.36123513, 0.62714877, 0.31002487, 0.62245933]]),\n",
       "        0,\n",
       "        0,\n",
       "        array([[0.45511914, 0.69211224, 0.3208213 , 0.5       , 0.65475332,\n",
       "                0.36123513, 0.62714877, 0.31002487, 0.62245933, 0.30153556]]),\n",
       "        False),\n",
       "       (array([[0.45511914, 0.69211224, 0.3208213 , 0.5       , 0.65475332,\n",
       "                0.36123513, 0.62714877, 0.31002487, 0.62245933, 0.30153556]]),\n",
       "        0,\n",
       "        0,\n",
       "        array([[0.69211224, 0.3208213 , 0.5       , 0.65475332, 0.36123513,\n",
       "                0.62714877, 0.31002487, 0.62245933, 0.30153556, 0.69635532]]),\n",
       "        False),\n",
       "       (array([[0.69211224, 0.3208213 , 0.5       , 0.65475332, 0.36123513,\n",
       "                0.62714877, 0.31002487, 0.62245933, 0.30153556, 0.69635532]]),\n",
       "        2,\n",
       "        0,\n",
       "        array([[0.3208213 , 0.5       , 0.65475332, 0.36123513, 0.62714877,\n",
       "                0.31002487, 0.62245933, 0.30153556, 0.69635532, 0.35663219]]),\n",
       "        False),\n",
       "       (array([[0.3208213 , 0.5       , 0.65475332, 0.36123513, 0.62714877,\n",
       "                0.31002487, 0.62245933, 0.30153556, 0.69635532, 0.35663219]]),\n",
       "        2,\n",
       "        0,\n",
       "        array([[0.5       , 0.65475332, 0.36123513, 0.62714877, 0.31002487,\n",
       "                0.62245933, 0.30153556, 0.69635532, 0.35663219, 0.81000031]]),\n",
       "        False),\n",
       "       (array([[0.5       , 0.65475332, 0.36123513, 0.62714877, 0.31002487,\n",
       "                0.62245933, 0.30153556, 0.69635532, 0.35663219, 0.81000031]]),\n",
       "        0,\n",
       "        0,\n",
       "        array([[0.65475332, 0.36123513, 0.62714877, 0.31002487, 0.62245933,\n",
       "                0.30153556, 0.69635532, 0.35663219, 0.81000031, 0.87761124]]),\n",
       "        False),\n",
       "       (array([[0.65475332, 0.36123513, 0.62714877, 0.31002487, 0.62245933,\n",
       "                0.30153556, 0.69635532, 0.35663219, 0.81000031, 0.87761124]]),\n",
       "        1,\n",
       "        0,\n",
       "        array([[0.36123513, 0.62714877, 0.31002487, 0.62245933, 0.30153556,\n",
       "                0.69635532, 0.35663219, 0.81000031, 0.87761124, 0.440285  ]]),\n",
       "        False),\n",
       "       (array([[0.36123513, 0.62714877, 0.31002487, 0.62245933, 0.30153556,\n",
       "                0.69635532, 0.35663219, 0.81000031, 0.87761124, 0.440285  ]]),\n",
       "        2,\n",
       "        0,\n",
       "        array([[0.62714877, 0.31002487, 0.62245933, 0.30153556, 0.69635532,\n",
       "                0.35663219, 0.81000031, 0.87761124, 0.440285  , 0.41095942]]),\n",
       "        False),\n",
       "       (array([[0.62714877, 0.31002487, 0.62245933, 0.30153556, 0.69635532,\n",
       "                0.35663219, 0.81000031, 0.87761124, 0.440285  , 0.41095942]]),\n",
       "        2,\n",
       "        0,\n",
       "        array([[0.31002487, 0.62245933, 0.30153556, 0.69635532, 0.35663219,\n",
       "                0.81000031, 0.87761124, 0.440285  , 0.41095942, 0.19466187]]),\n",
       "        False),\n",
       "       (array([[0.31002487, 0.62245933, 0.30153556, 0.69635532, 0.35663219,\n",
       "                0.81000031, 0.87761124, 0.440285  , 0.41095942, 0.19466187]]),\n",
       "        0,\n",
       "        0,\n",
       "        array([[0.62245933, 0.30153556, 0.69635532, 0.35663219, 0.81000031,\n",
       "                0.87761124, 0.440285  , 0.41095942, 0.19466187, 0.4949991 ]]),\n",
       "        False),\n",
       "       (array([[0.62245933, 0.30153556, 0.69635532, 0.35663219, 0.81000031,\n",
       "                0.87761124, 0.440285  , 0.41095942, 0.19466187, 0.4949991 ]]),\n",
       "        0,\n",
       "        0,\n",
       "        array([[0.30153556, 0.69635532, 0.35663219, 0.81000031, 0.87761124,\n",
       "                0.440285  , 0.41095942, 0.19466187, 0.4949991 , 0.52248391]]),\n",
       "        False),\n",
       "       (array([[0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5]]),\n",
       "        0,\n",
       "        0,\n",
       "        array([[0.5       , 0.5       , 0.5       , 0.5       , 0.5       ,\n",
       "                0.5       , 0.5       , 0.5       , 0.5       , 0.79248934]]),\n",
       "        False),\n",
       "       (array([[0.5       , 0.5       , 0.5       , 0.5       , 0.5       ,\n",
       "                0.5       , 0.5       , 0.5       , 0.5       , 0.79248934]]),\n",
       "        0,\n",
       "        0,\n",
       "        array([[0.5       , 0.5       , 0.5       , 0.5       , 0.5       ,\n",
       "                0.5       , 0.5       , 0.5       , 0.79248934, 0.45511914]]),\n",
       "        False),\n",
       "       (array([[0.5       , 0.5       , 0.5       , 0.5       , 0.5       ,\n",
       "                0.5       , 0.5       , 0.5       , 0.79248934, 0.45511914]]),\n",
       "        0,\n",
       "        0,\n",
       "        array([[0.5       , 0.5       , 0.5       , 0.5       , 0.5       ,\n",
       "                0.5       , 0.5       , 0.79248934, 0.45511914, 0.69211224]]),\n",
       "        False),\n",
       "       (array([[0.5       , 0.5       , 0.5       , 0.5       , 0.5       ,\n",
       "                0.5       , 0.5       , 0.79248934, 0.45511914, 0.69211224]]),\n",
       "        2,\n",
       "        0,\n",
       "        array([[0.5       , 0.5       , 0.5       , 0.5       , 0.5       ,\n",
       "                0.5       , 0.79248934, 0.45511914, 0.69211224, 0.3208213 ]]),\n",
       "        False),\n",
       "       (array([[0.5       , 0.5       , 0.5       , 0.5       , 0.5       ,\n",
       "                0.5       , 0.79248934, 0.45511914, 0.69211224, 0.3208213 ]]),\n",
       "        1,\n",
       "        0,\n",
       "        array([[0.5       , 0.5       , 0.5       , 0.5       , 0.5       ,\n",
       "                0.79248934, 0.45511914, 0.69211224, 0.3208213 , 0.5       ]]),\n",
       "        False),\n",
       "       (array([[0.5       , 0.5       , 0.5       , 0.5       , 0.5       ,\n",
       "                0.79248934, 0.45511914, 0.69211224, 0.3208213 , 0.5       ]]),\n",
       "        1,\n",
       "        0,\n",
       "        array([[0.5       , 0.5       , 0.5       , 0.5       , 0.79248934,\n",
       "                0.45511914, 0.69211224, 0.3208213 , 0.5       , 0.65475332]]),\n",
       "        False),\n",
       "       (array([[0.5       , 0.5       , 0.5       , 0.5       , 0.79248934,\n",
       "                0.45511914, 0.69211224, 0.3208213 , 0.5       , 0.65475332]]),\n",
       "        0,\n",
       "        0,\n",
       "        array([[0.5       , 0.5       , 0.5       , 0.79248934, 0.45511914,\n",
       "                0.69211224, 0.3208213 , 0.5       , 0.65475332, 0.36123513]]),\n",
       "        False),\n",
       "       (array([[0.5       , 0.5       , 0.5       , 0.79248934, 0.45511914,\n",
       "                0.69211224, 0.3208213 , 0.5       , 0.65475332, 0.36123513]]),\n",
       "        1,\n",
       "        0,\n",
       "        array([[0.5       , 0.5       , 0.79248934, 0.45511914, 0.69211224,\n",
       "                0.3208213 , 0.5       , 0.65475332, 0.36123513, 0.62714877]]),\n",
       "        False),\n",
       "       (array([[0.5       , 0.5       , 0.79248934, 0.45511914, 0.69211224,\n",
       "                0.3208213 , 0.5       , 0.65475332, 0.36123513, 0.62714877]]),\n",
       "        2,\n",
       "        0.589996337890625,\n",
       "        array([[0.5       , 0.79248934, 0.45511914, 0.69211224, 0.3208213 ,\n",
       "                0.5       , 0.65475332, 0.36123513, 0.62714877, 0.31002487]]),\n",
       "        False),\n",
       "       (array([[0.5       , 0.79248934, 0.45511914, 0.69211224, 0.3208213 ,\n",
       "                0.5       , 0.65475332, 0.36123513, 0.62714877, 0.31002487]]),\n",
       "        1,\n",
       "        0,\n",
       "        array([[0.79248934, 0.45511914, 0.69211224, 0.3208213 , 0.5       ,\n",
       "                0.65475332, 0.36123513, 0.62714877, 0.31002487, 0.62245933]]),\n",
       "        False),\n",
       "       (array([[0.79248934, 0.45511914, 0.69211224, 0.3208213 , 0.5       ,\n",
       "                0.65475332, 0.36123513, 0.62714877, 0.31002487, 0.62245933]]),\n",
       "        1,\n",
       "        0,\n",
       "        array([[0.45511914, 0.69211224, 0.3208213 , 0.5       , 0.65475332,\n",
       "                0.36123513, 0.62714877, 0.31002487, 0.62245933, 0.30153556]]),\n",
       "        False),\n",
       "       (array([[0.45511914, 0.69211224, 0.3208213 , 0.5       , 0.65475332,\n",
       "                0.36123513, 0.62714877, 0.31002487, 0.62245933, 0.30153556]]),\n",
       "        1,\n",
       "        0,\n",
       "        array([[0.69211224, 0.3208213 , 0.5       , 0.65475332, 0.36123513,\n",
       "                0.62714877, 0.31002487, 0.62245933, 0.30153556, 0.69635532]]),\n",
       "        False),\n",
       "       (array([[0.69211224, 0.3208213 , 0.5       , 0.65475332, 0.36123513,\n",
       "                0.62714877, 0.31002487, 0.62245933, 0.30153556, 0.69635532]]),\n",
       "        1,\n",
       "        0,\n",
       "        array([[0.3208213 , 0.5       , 0.65475332, 0.36123513, 0.62714877,\n",
       "                0.31002487, 0.62245933, 0.30153556, 0.69635532, 0.35663219]]),\n",
       "        False),\n",
       "       (array([[0.3208213 , 0.5       , 0.65475332, 0.36123513, 0.62714877,\n",
       "                0.31002487, 0.62245933, 0.30153556, 0.69635532, 0.35663219]]),\n",
       "        0,\n",
       "        0,\n",
       "        array([[0.5       , 0.65475332, 0.36123513, 0.62714877, 0.31002487,\n",
       "                0.62245933, 0.30153556, 0.69635532, 0.35663219, 0.81000031]]),\n",
       "        False),\n",
       "       (array([[0.5       , 0.65475332, 0.36123513, 0.62714877, 0.31002487,\n",
       "                0.62245933, 0.30153556, 0.69635532, 0.35663219, 0.81000031]]),\n",
       "        0,\n",
       "        0,\n",
       "        array([[0.65475332, 0.36123513, 0.62714877, 0.31002487, 0.62245933,\n",
       "                0.30153556, 0.69635532, 0.35663219, 0.81000031, 0.87761124]]),\n",
       "        False),\n",
       "       (array([[0.65475332, 0.36123513, 0.62714877, 0.31002487, 0.62245933,\n",
       "                0.30153556, 0.69635532, 0.35663219, 0.81000031, 0.87761124]]),\n",
       "        0,\n",
       "        0,\n",
       "        array([[0.36123513, 0.62714877, 0.31002487, 0.62245933, 0.30153556,\n",
       "                0.69635532, 0.35663219, 0.81000031, 0.87761124, 0.440285  ]]),\n",
       "        False),\n",
       "       (array([[0.36123513, 0.62714877, 0.31002487, 0.62245933, 0.30153556,\n",
       "                0.69635532, 0.35663219, 0.81000031, 0.87761124, 0.440285  ]]),\n",
       "        0,\n",
       "        0,\n",
       "        array([[0.62714877, 0.31002487, 0.62245933, 0.30153556, 0.69635532,\n",
       "                0.35663219, 0.81000031, 0.87761124, 0.440285  , 0.41095942]]),\n",
       "        False),\n",
       "       (array([[0.62714877, 0.31002487, 0.62245933, 0.30153556, 0.69635532,\n",
       "                0.35663219, 0.81000031, 0.87761124, 0.440285  , 0.41095942]]),\n",
       "        2,\n",
       "        2.5099945068359375,\n",
       "        array([[0.31002487, 0.62245933, 0.30153556, 0.69635532, 0.35663219,\n",
       "                0.81000031, 0.87761124, 0.440285  , 0.41095942, 0.19466187]]),\n",
       "        False),\n",
       "       (array([[0.31002487, 0.62245933, 0.30153556, 0.69635532, 0.35663219,\n",
       "                0.81000031, 0.87761124, 0.440285  , 0.41095942, 0.19466187]]),\n",
       "        1,\n",
       "        0,\n",
       "        array([[0.62245933, 0.30153556, 0.69635532, 0.35663219, 0.81000031,\n",
       "                0.87761124, 0.440285  , 0.41095942, 0.19466187, 0.4949991 ]]),\n",
       "        False),\n",
       "       (array([[0.62245933, 0.30153556, 0.69635532, 0.35663219, 0.81000031,\n",
       "                0.87761124, 0.440285  , 0.41095942, 0.19466187, 0.4949991 ]]),\n",
       "        1,\n",
       "        0,\n",
       "        array([[0.30153556, 0.69635532, 0.35663219, 0.81000031, 0.87761124,\n",
       "                0.440285  , 0.41095942, 0.19466187, 0.4949991 , 0.52248391]]),\n",
       "        False),\n",
       "       (array([[0.30153556, 0.69635532, 0.35663219, 0.81000031, 0.87761124,\n",
       "                0.440285  , 0.41095942, 0.19466187, 0.4949991 , 0.52248391]]),\n",
       "        1,\n",
       "        0,\n",
       "        array([[0.69635532, 0.35663219, 0.81000031, 0.87761124, 0.440285  ,\n",
       "                0.41095942, 0.19466187, 0.4949991 , 0.52248391, 0.53743212]]),\n",
       "        False),\n",
       "       (array([[0.69635532, 0.35663219, 0.81000031, 0.87761124, 0.440285  ,\n",
       "                0.41095942, 0.19466187, 0.4949991 , 0.52248391, 0.53743212]]),\n",
       "        1,\n",
       "        0,\n",
       "        array([[0.35663219, 0.81000031, 0.87761124, 0.440285  , 0.41095942,\n",
       "                0.19466187, 0.4949991 , 0.52248391, 0.53743212, 0.82778248]]),\n",
       "        False),\n",
       "       (array([[0.35663219, 0.81000031, 0.87761124, 0.440285  , 0.41095942,\n",
       "                0.19466187, 0.4949991 , 0.52248391, 0.53743212, 0.82778248]]),\n",
       "        0,\n",
       "        0,\n",
       "        array([[0.81000031, 0.87761124, 0.440285  , 0.41095942, 0.19466187,\n",
       "                0.4949991 , 0.52248391, 0.53743212, 0.82778248, 0.39891124]]),\n",
       "        False),\n",
       "       (array([[0.81000031, 0.87761124, 0.440285  , 0.41095942, 0.19466187,\n",
       "                0.4949991 , 0.52248391, 0.53743212, 0.82778248, 0.39891124]]),\n",
       "        2,\n",
       "        2.399993896484375,\n",
       "        array([[0.87761124, 0.440285  , 0.41095942, 0.19466187, 0.4949991 ,\n",
       "                0.52248391, 0.53743212, 0.82778248, 0.39891124, 0.50250242]]),\n",
       "        False),\n",
       "       (array([[0.87761124, 0.440285  , 0.41095942, 0.19466187, 0.4949991 ,\n",
       "                0.52248391, 0.53743212, 0.82778248, 0.39891124, 0.50250242]]),\n",
       "        1,\n",
       "        0,\n",
       "        array([[0.440285  , 0.41095942, 0.19466187, 0.4949991 , 0.52248391,\n",
       "                0.53743212, 0.82778248, 0.39891124, 0.50250242, 0.57444326]]),\n",
       "        False),\n",
       "       (array([[0.440285  , 0.41095942, 0.19466187, 0.4949991 , 0.52248391,\n",
       "                0.53743212, 0.82778248, 0.39891124, 0.50250242, 0.57444326]]),\n",
       "        1,\n",
       "        0,\n",
       "        array([[0.41095942, 0.19466187, 0.4949991 , 0.52248391, 0.53743212,\n",
       "                0.82778248, 0.39891124, 0.50250242, 0.57444326, 0.7957598 ]]),\n",
       "        False),\n",
       "       (array([[0.41095942, 0.19466187, 0.4949991 , 0.52248391, 0.53743212,\n",
       "                0.82778248, 0.39891124, 0.50250242, 0.57444326, 0.7957598 ]]),\n",
       "        2,\n",
       "        4.350006103515625,\n",
       "        array([[0.19466187, 0.4949991 , 0.52248391, 0.53743212, 0.82778248,\n",
       "                0.39891124, 0.50250242, 0.57444326, 0.7957598 , 0.71299779]]),\n",
       "        False),\n",
       "       (array([[0.19466187, 0.4949991 , 0.52248391, 0.53743212, 0.82778248,\n",
       "                0.39891124, 0.50250242, 0.57444326, 0.7957598 , 0.71299779]]),\n",
       "        2,\n",
       "        4.7599945068359375,\n",
       "        array([[0.4949991 , 0.52248391, 0.53743212, 0.82778248, 0.39891124,\n",
       "                0.50250242, 0.57444326, 0.7957598 , 0.71299779, 0.77902779]]),\n",
       "        False),\n",
       "       (array([[0.4949991 , 0.52248391, 0.53743212, 0.82778248, 0.39891124,\n",
       "                0.50250242, 0.57444326, 0.7957598 , 0.71299779, 0.77902779]]),\n",
       "        2,\n",
       "        6.8600006103515625,\n",
       "        array([[0.52248391, 0.53743212, 0.82778248, 0.39891124, 0.50250242,\n",
       "                0.57444326, 0.7957598 , 0.71299779, 0.77902779, 0.7170738 ]]),\n",
       "        False),\n",
       "       (array([[0.52248391, 0.53743212, 0.82778248, 0.39891124, 0.50250242,\n",
       "                0.57444326, 0.7957598 , 0.71299779, 0.77902779, 0.7170738 ]]),\n",
       "        1,\n",
       "        0,\n",
       "        array([[0.53743212, 0.82778248, 0.39891124, 0.50250242, 0.57444326,\n",
       "                0.7957598 , 0.71299779, 0.77902779, 0.7170738 , 0.77206376]]),\n",
       "        False),\n",
       "       (array([[0.53743212, 0.82778248, 0.39891124, 0.50250242, 0.57444326,\n",
       "                0.7957598 , 0.71299779, 0.77902779, 0.7170738 , 0.77206376]]),\n",
       "        0,\n",
       "        0,\n",
       "        array([[0.82778248, 0.39891124, 0.50250242, 0.57444326, 0.7957598 ,\n",
       "                0.71299779, 0.77902779, 0.7170738 , 0.77206376, 0.45016676]]),\n",
       "        False),\n",
       "       (array([[0.82778248, 0.39891124, 0.50250242, 0.57444326, 0.7957598 ,\n",
       "                0.71299779, 0.77902779, 0.7170738 , 0.77206376, 0.45016676]]),\n",
       "        0,\n",
       "        0,\n",
       "        array([[0.39891124, 0.50250242, 0.57444326, 0.7957598 , 0.71299779,\n",
       "                0.77902779, 0.7170738 , 0.77206376, 0.45016676, 0.5914578 ]]),\n",
       "        False),\n",
       "       (array([[0.39891124, 0.50250242, 0.57444326, 0.7957598 , 0.71299779,\n",
       "                0.77902779, 0.7170738 , 0.77206376, 0.45016676, 0.5914578 ]]),\n",
       "        0,\n",
       "        0,\n",
       "        array([[0.50250242, 0.57444326, 0.7957598 , 0.71299779, 0.77902779,\n",
       "                0.7170738 , 0.77206376, 0.45016676, 0.5914578 , 0.80218534]]),\n",
       "        False),\n",
       "       (array([[0.50250242, 0.57444326, 0.7957598 , 0.71299779, 0.77902779,\n",
       "                0.7170738 , 0.77206376, 0.45016676, 0.5914578 , 0.80218534]]),\n",
       "        2,\n",
       "        9.75,\n",
       "        array([[0.57444326, 0.7957598 , 0.71299779, 0.77902779, 0.7170738 ,\n",
       "                0.77206376, 0.45016676, 0.5914578 , 0.80218534, 0.44769043]]),\n",
       "        False),\n",
       "       (array([[0.57444326, 0.7957598 , 0.71299779, 0.77902779, 0.7170738 ,\n",
       "                0.77206376, 0.45016676, 0.5914578 , 0.80218534, 0.44769043]]),\n",
       "        1,\n",
       "        0,\n",
       "        array([[0.7957598 , 0.71299779, 0.77902779, 0.7170738 , 0.77206376,\n",
       "                0.45016676, 0.5914578 , 0.80218534, 0.44769043, 0.53991579]]),\n",
       "        False),\n",
       "       (array([[0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5]]),\n",
       "        0,\n",
       "        0,\n",
       "        array([[0.5       , 0.5       , 0.5       , 0.5       , 0.5       ,\n",
       "                0.5       , 0.5       , 0.5       , 0.5       , 0.79248934]]),\n",
       "        False),\n",
       "       (array([[0.5       , 0.5       , 0.5       , 0.5       , 0.5       ,\n",
       "                0.5       , 0.5       , 0.5       , 0.5       , 0.79248934]]),\n",
       "        0,\n",
       "        0,\n",
       "        array([[0.5       , 0.5       , 0.5       , 0.5       , 0.5       ,\n",
       "                0.5       , 0.5       , 0.5       , 0.79248934, 0.45511914]]),\n",
       "        False),\n",
       "       (array([[0.5       , 0.5       , 0.5       , 0.5       , 0.5       ,\n",
       "                0.5       , 0.5       , 0.5       , 0.79248934, 0.45511914]]),\n",
       "        2,\n",
       "        0,\n",
       "        array([[0.5       , 0.5       , 0.5       , 0.5       , 0.5       ,\n",
       "                0.5       , 0.5       , 0.79248934, 0.45511914, 0.69211224]]),\n",
       "        False),\n",
       "       (array([[0.5       , 0.5       , 0.5       , 0.5       , 0.5       ,\n",
       "                0.5       , 0.5       , 0.79248934, 0.45511914, 0.69211224]]),\n",
       "        2,\n",
       "        0,\n",
       "        array([[0.5       , 0.5       , 0.5       , 0.5       , 0.5       ,\n",
       "                0.5       , 0.79248934, 0.45511914, 0.69211224, 0.3208213 ]]),\n",
       "        False),\n",
       "       (array([[0.5       , 0.5       , 0.5       , 0.5       , 0.5       ,\n",
       "                0.5       , 0.79248934, 0.45511914, 0.69211224, 0.3208213 ]]),\n",
       "        2,\n",
       "        0,\n",
       "        array([[0.5       , 0.5       , 0.5       , 0.5       , 0.5       ,\n",
       "                0.79248934, 0.45511914, 0.69211224, 0.3208213 , 0.5       ]]),\n",
       "        False),\n",
       "       (array([[0.5       , 0.5       , 0.5       , 0.5       , 0.5       ,\n",
       "                0.79248934, 0.45511914, 0.69211224, 0.3208213 , 0.5       ]]),\n",
       "        0,\n",
       "        0,\n",
       "        array([[0.5       , 0.5       , 0.5       , 0.5       , 0.79248934,\n",
       "                0.45511914, 0.69211224, 0.3208213 , 0.5       , 0.65475332]]),\n",
       "        False),\n",
       "       (array([[0.5       , 0.5       , 0.5       , 0.5       , 0.79248934,\n",
       "                0.45511914, 0.69211224, 0.3208213 , 0.5       , 0.65475332]]),\n",
       "        1,\n",
       "        0,\n",
       "        array([[0.5       , 0.5       , 0.5       , 0.79248934, 0.45511914,\n",
       "                0.69211224, 0.3208213 , 0.5       , 0.65475332, 0.36123513]]),\n",
       "        False),\n",
       "       (array([[0.5       , 0.5       , 0.5       , 0.79248934, 0.45511914,\n",
       "                0.69211224, 0.3208213 , 0.5       , 0.65475332, 0.36123513]]),\n",
       "        2,\n",
       "        0,\n",
       "        array([[0.5       , 0.5       , 0.79248934, 0.45511914, 0.69211224,\n",
       "                0.3208213 , 0.5       , 0.65475332, 0.36123513, 0.62714877]]),\n",
       "        False),\n",
       "       (array([[0.5       , 0.5       , 0.79248934, 0.45511914, 0.69211224,\n",
       "                0.3208213 , 0.5       , 0.65475332, 0.36123513, 0.62714877]]),\n",
       "        2,\n",
       "        0,\n",
       "        array([[0.5       , 0.79248934, 0.45511914, 0.69211224, 0.3208213 ,\n",
       "                0.5       , 0.65475332, 0.36123513, 0.62714877, 0.31002487]]),\n",
       "        False),\n",
       "       (array([[0.5       , 0.79248934, 0.45511914, 0.69211224, 0.3208213 ,\n",
       "                0.5       , 0.65475332, 0.36123513, 0.62714877, 0.31002487]]),\n",
       "        1,\n",
       "        0,\n",
       "        array([[0.79248934, 0.45511914, 0.69211224, 0.3208213 , 0.5       ,\n",
       "                0.65475332, 0.36123513, 0.62714877, 0.31002487, 0.62245933]]),\n",
       "        False),\n",
       "       (array([[0.79248934, 0.45511914, 0.69211224, 0.3208213 , 0.5       ,\n",
       "                0.65475332, 0.36123513, 0.62714877, 0.31002487, 0.62245933]]),\n",
       "        2,\n",
       "        0.5,\n",
       "        array([[0.45511914, 0.69211224, 0.3208213 , 0.5       , 0.65475332,\n",
       "                0.36123513, 0.62714877, 0.31002487, 0.62245933, 0.30153556]]),\n",
       "        False),\n",
       "       (array([[0.45511914, 0.69211224, 0.3208213 , 0.5       , 0.65475332,\n",
       "                0.36123513, 0.62714877, 0.31002487, 0.62245933, 0.30153556]]),\n",
       "        2,\n",
       "        0,\n",
       "        array([[0.69211224, 0.3208213 , 0.5       , 0.65475332, 0.36123513,\n",
       "                0.62714877, 0.31002487, 0.62245933, 0.30153556, 0.69635532]]),\n",
       "        False),\n",
       "       (array([[0.69211224, 0.3208213 , 0.5       , 0.65475332, 0.36123513,\n",
       "                0.62714877, 0.31002487, 0.62245933, 0.30153556, 0.69635532]]),\n",
       "        0,\n",
       "        0,\n",
       "        array([[0.3208213 , 0.5       , 0.65475332, 0.36123513, 0.62714877,\n",
       "                0.31002487, 0.62245933, 0.30153556, 0.69635532, 0.35663219]]),\n",
       "        False),\n",
       "       (array([[0.3208213 , 0.5       , 0.65475332, 0.36123513, 0.62714877,\n",
       "                0.31002487, 0.62245933, 0.30153556, 0.69635532, 0.35663219]]),\n",
       "        1,\n",
       "        0,\n",
       "        array([[0.5       , 0.65475332, 0.36123513, 0.62714877, 0.31002487,\n",
       "                0.62245933, 0.30153556, 0.69635532, 0.35663219, 0.81000031]]),\n",
       "        False),\n",
       "       (array([[0.5       , 0.65475332, 0.36123513, 0.62714877, 0.31002487,\n",
       "                0.62245933, 0.30153556, 0.69635532, 0.35663219, 0.81000031]]),\n",
       "        1,\n",
       "        0,\n",
       "        array([[0.65475332, 0.36123513, 0.62714877, 0.31002487, 0.62245933,\n",
       "                0.30153556, 0.69635532, 0.35663219, 0.81000031, 0.87761124]]),\n",
       "        False),\n",
       "       (array([[0.65475332, 0.36123513, 0.62714877, 0.31002487, 0.62245933,\n",
       "                0.30153556, 0.69635532, 0.35663219, 0.81000031, 0.87761124]]),\n",
       "        2,\n",
       "        3.420013427734375,\n",
       "        array([[0.36123513, 0.62714877, 0.31002487, 0.62245933, 0.30153556,\n",
       "                0.69635532, 0.35663219, 0.81000031, 0.87761124, 0.440285  ]]),\n",
       "        False),\n",
       "       (array([[0.36123513, 0.62714877, 0.31002487, 0.62245933, 0.30153556,\n",
       "                0.69635532, 0.35663219, 0.81000031, 0.87761124, 0.440285  ]]),\n",
       "        0,\n",
       "        0,\n",
       "        array([[0.62714877, 0.31002487, 0.62245933, 0.30153556, 0.69635532,\n",
       "                0.35663219, 0.81000031, 0.87761124, 0.440285  , 0.41095942]]),\n",
       "        False),\n",
       "       (array([[0.62714877, 0.31002487, 0.62245933, 0.30153556, 0.69635532,\n",
       "                0.35663219, 0.81000031, 0.87761124, 0.440285  , 0.41095942]]),\n",
       "        0,\n",
       "        0,\n",
       "        array([[0.31002487, 0.62245933, 0.30153556, 0.69635532, 0.35663219,\n",
       "                0.81000031, 0.87761124, 0.440285  , 0.41095942, 0.19466187]]),\n",
       "        False),\n",
       "       (array([[0.31002487, 0.62245933, 0.30153556, 0.69635532, 0.35663219,\n",
       "                0.81000031, 0.87761124, 0.440285  , 0.41095942, 0.19466187]]),\n",
       "        2,\n",
       "        0,\n",
       "        array([[0.62245933, 0.30153556, 0.69635532, 0.35663219, 0.81000031,\n",
       "                0.87761124, 0.440285  , 0.41095942, 0.19466187, 0.4949991 ]]),\n",
       "        False),\n",
       "       (array([[0.62245933, 0.30153556, 0.69635532, 0.35663219, 0.81000031,\n",
       "                0.87761124, 0.440285  , 0.41095942, 0.19466187, 0.4949991 ]]),\n",
       "        1,\n",
       "        0,\n",
       "        array([[0.30153556, 0.69635532, 0.35663219, 0.81000031, 0.87761124,\n",
       "                0.440285  , 0.41095942, 0.19466187, 0.4949991 , 0.52248391]]),\n",
       "        False),\n",
       "       (array([[0.30153556, 0.69635532, 0.35663219, 0.81000031, 0.87761124,\n",
       "                0.440285  , 0.41095942, 0.19466187, 0.4949991 , 0.52248391]]),\n",
       "        0,\n",
       "        0,\n",
       "        array([[0.69635532, 0.35663219, 0.81000031, 0.87761124, 0.440285  ,\n",
       "                0.41095942, 0.19466187, 0.4949991 , 0.52248391, 0.53743212]]),\n",
       "        False),\n",
       "       (array([[0.69635532, 0.35663219, 0.81000031, 0.87761124, 0.440285  ,\n",
       "                0.41095942, 0.19466187, 0.4949991 , 0.52248391, 0.53743212]]),\n",
       "        1,\n",
       "        0,\n",
       "        array([[0.35663219, 0.81000031, 0.87761124, 0.440285  , 0.41095942,\n",
       "                0.19466187, 0.4949991 , 0.52248391, 0.53743212, 0.82778248]]),\n",
       "        False),\n",
       "       (array([[0.35663219, 0.81000031, 0.87761124, 0.440285  , 0.41095942,\n",
       "                0.19466187, 0.4949991 , 0.52248391, 0.53743212, 0.82778248]]),\n",
       "        2,\n",
       "        1.80999755859375,\n",
       "        array([[0.81000031, 0.87761124, 0.440285  , 0.41095942, 0.19466187,\n",
       "                0.4949991 , 0.52248391, 0.53743212, 0.82778248, 0.39891124]]),\n",
       "        False),\n",
       "       (array([[0.81000031, 0.87761124, 0.440285  , 0.41095942, 0.19466187,\n",
       "                0.4949991 , 0.52248391, 0.53743212, 0.82778248, 0.39891124]]),\n",
       "        2,\n",
       "        1.1599884033203125,\n",
       "        array([[0.87761124, 0.440285  , 0.41095942, 0.19466187, 0.4949991 ,\n",
       "                0.52248391, 0.53743212, 0.82778248, 0.39891124, 0.50250242]]),\n",
       "        False),\n",
       "       (array([[0.87761124, 0.440285  , 0.41095942, 0.19466187, 0.4949991 ,\n",
       "                0.52248391, 0.53743212, 0.82778248, 0.39891124, 0.50250242]]),\n",
       "        2,\n",
       "        0,\n",
       "        array([[0.440285  , 0.41095942, 0.19466187, 0.4949991 , 0.52248391,\n",
       "                0.53743212, 0.82778248, 0.39891124, 0.50250242, 0.57444326]]),\n",
       "        False),\n",
       "       (array([[0.440285  , 0.41095942, 0.19466187, 0.4949991 , 0.52248391,\n",
       "                0.53743212, 0.82778248, 0.39891124, 0.50250242, 0.57444326]]),\n",
       "        0,\n",
       "        0,\n",
       "        array([[0.41095942, 0.19466187, 0.4949991 , 0.52248391, 0.53743212,\n",
       "                0.82778248, 0.39891124, 0.50250242, 0.57444326, 0.7957598 ]]),\n",
       "        False),\n",
       "       (array([[0.41095942, 0.19466187, 0.4949991 , 0.52248391, 0.53743212,\n",
       "                0.82778248, 0.39891124, 0.50250242, 0.57444326, 0.7957598 ]]),\n",
       "        2,\n",
       "        0,\n",
       "        array([[0.19466187, 0.4949991 , 0.52248391, 0.53743212, 0.82778248,\n",
       "                0.39891124, 0.50250242, 0.57444326, 0.7957598 , 0.71299779]]),\n",
       "        False),\n",
       "       (array([[0.19466187, 0.4949991 , 0.52248391, 0.53743212, 0.82778248,\n",
       "                0.39891124, 0.50250242, 0.57444326, 0.7957598 , 0.71299779]]),\n",
       "        1,\n",
       "        0,\n",
       "        array([[0.4949991 , 0.52248391, 0.53743212, 0.82778248, 0.39891124,\n",
       "                0.50250242, 0.57444326, 0.7957598 , 0.71299779, 0.77902779]]),\n",
       "        False),\n",
       "       (array([[0.4949991 , 0.52248391, 0.53743212, 0.82778248, 0.39891124,\n",
       "                0.50250242, 0.57444326, 0.7957598 , 0.71299779, 0.77902779]]),\n",
       "        2,\n",
       "        1.260009765625,\n",
       "        array([[0.52248391, 0.53743212, 0.82778248, 0.39891124, 0.50250242,\n",
       "                0.57444326, 0.7957598 , 0.71299779, 0.77902779, 0.7170738 ]]),\n",
       "        False),\n",
       "       (array([[0.52248391, 0.53743212, 0.82778248, 0.39891124, 0.50250242,\n",
       "                0.57444326, 0.7957598 , 0.71299779, 0.77902779, 0.7170738 ]]),\n",
       "        2,\n",
       "        0,\n",
       "        array([[0.53743212, 0.82778248, 0.39891124, 0.50250242, 0.57444326,\n",
       "                0.7957598 , 0.71299779, 0.77902779, 0.7170738 , 0.77206376]]),\n",
       "        False),\n",
       "       (array([[0.53743212, 0.82778248, 0.39891124, 0.50250242, 0.57444326,\n",
       "                0.7957598 , 0.71299779, 0.77902779, 0.7170738 , 0.77206376]]),\n",
       "        1,\n",
       "        0,\n",
       "        array([[0.82778248, 0.39891124, 0.50250242, 0.57444326, 0.7957598 ,\n",
       "                0.71299779, 0.77902779, 0.7170738 , 0.77206376, 0.45016676]]),\n",
       "        False),\n",
       "       (array([[0.82778248, 0.39891124, 0.50250242, 0.57444326, 0.7957598 ,\n",
       "                0.71299779, 0.77902779, 0.7170738 , 0.77206376, 0.45016676]]),\n",
       "        1,\n",
       "        0,\n",
       "        array([[0.39891124, 0.50250242, 0.57444326, 0.7957598 , 0.71299779,\n",
       "                0.77902779, 0.7170738 , 0.77206376, 0.45016676, 0.5914578 ]]),\n",
       "        False),\n",
       "       (array([[0.39891124, 0.50250242, 0.57444326, 0.7957598 , 0.71299779,\n",
       "                0.77902779, 0.7170738 , 0.77206376, 0.45016676, 0.5914578 ]]),\n",
       "        2,\n",
       "        0.1699981689453125,\n",
       "        array([[0.50250242, 0.57444326, 0.7957598 , 0.71299779, 0.77902779,\n",
       "                0.7170738 , 0.77206376, 0.45016676, 0.5914578 , 0.80218534]]),\n",
       "        False),\n",
       "       (array([[0.50250242, 0.57444326, 0.7957598 , 0.71299779, 0.77902779,\n",
       "                0.7170738 , 0.77206376, 0.45016676, 0.5914578 , 0.80218534]]),\n",
       "        0,\n",
       "        0,\n",
       "        array([[0.57444326, 0.7957598 , 0.71299779, 0.77902779, 0.7170738 ,\n",
       "                0.77206376, 0.45016676, 0.5914578 , 0.80218534, 0.44769043]]),\n",
       "        False),\n",
       "       (array([[0.57444326, 0.7957598 , 0.71299779, 0.77902779, 0.7170738 ,\n",
       "                0.77206376, 0.45016676, 0.5914578 , 0.80218534, 0.44769043]]),\n",
       "        1,\n",
       "        0,\n",
       "        array([[0.7957598 , 0.71299779, 0.77902779, 0.7170738 , 0.77206376,\n",
       "                0.45016676, 0.5914578 , 0.80218534, 0.44769043, 0.53991579]]),\n",
       "        False),\n",
       "       (array([[0.7957598 , 0.71299779, 0.77902779, 0.7170738 , 0.77206376,\n",
       "                0.45016676, 0.5914578 , 0.80218534, 0.44769043, 0.53991579]]),\n",
       "        0,\n",
       "        0,\n",
       "        array([[0.71299779, 0.77902779, 0.7170738 , 0.77206376, 0.45016676,\n",
       "                0.5914578 , 0.80218534, 0.44769043, 0.53991579, 0.57444326]]),\n",
       "        False),\n",
       "       (array([[0.71299779, 0.77902779, 0.7170738 , 0.77206376, 0.45016676,\n",
       "                0.5914578 , 0.80218534, 0.44769043, 0.53991579, 0.57444326]]),\n",
       "        0,\n",
       "        0,\n",
       "        array([[0.77902779, 0.7170738 , 0.77206376, 0.45016676, 0.5914578 ,\n",
       "                0.80218534, 0.44769043, 0.53991579, 0.57444326, 0.5914578 ]]),\n",
       "        False),\n",
       "       (array([[0.77902779, 0.7170738 , 0.77206376, 0.45016676, 0.5914578 ,\n",
       "                0.80218534, 0.44769043, 0.53991579, 0.57444326, 0.5914578 ]]),\n",
       "        1,\n",
       "        0,\n",
       "        array([[0.7170738 , 0.77206376, 0.45016676, 0.5914578 , 0.80218534,\n",
       "                0.44769043, 0.53991579, 0.57444326, 0.5914578 , 0.34524668]]),\n",
       "        False),\n",
       "       (array([[0.7170738 , 0.77206376, 0.45016676, 0.5914578 , 0.80218534,\n",
       "                0.44769043, 0.53991579, 0.57444326, 0.5914578 , 0.34524668]]),\n",
       "        1,\n",
       "        0,\n",
       "        array([[0.77206376, 0.45016676, 0.5914578 , 0.80218534, 0.44769043,\n",
       "                0.53991579, 0.57444326, 0.5914578 , 0.34524668, 0.9647702 ]]),\n",
       "        False),\n",
       "       (array([[0.77206376, 0.45016676, 0.5914578 , 0.80218534, 0.44769043,\n",
       "                0.53991579, 0.57444326, 0.5914578 , 0.34524668, 0.9647702 ]]),\n",
       "        0,\n",
       "        0,\n",
       "        array([[0.45016676, 0.5914578 , 0.80218534, 0.44769043, 0.53991579,\n",
       "                0.57444326, 0.5914578 , 0.34524668, 0.9647702 , 0.18093961]]),\n",
       "        False),\n",
       "       (array([[0.45016676, 0.5914578 , 0.80218534, 0.44769043, 0.53991579,\n",
       "                0.57444326, 0.5914578 , 0.34524668, 0.9647702 , 0.18093961]]),\n",
       "        1,\n",
       "        0,\n",
       "        array([[0.5914578 , 0.80218534, 0.44769043, 0.53991579, 0.57444326,\n",
       "                0.5914578 , 0.34524668, 0.9647702 , 0.18093961, 0.53742833]]),\n",
       "        False),\n",
       "       (array([[0.5914578 , 0.80218534, 0.44769043, 0.53991579, 0.57444326,\n",
       "                0.5914578 , 0.34524668, 0.9647702 , 0.18093961, 0.53742833]]),\n",
       "        2,\n",
       "        3.6999969482421875,\n",
       "        array([[0.80218534, 0.44769043, 0.53991579, 0.57444326, 0.5914578 ,\n",
       "                0.34524668, 0.9647702 , 0.18093961, 0.53742833, 0.32960073]]),\n",
       "        False),\n",
       "       (array([[0.80218534, 0.44769043, 0.53991579, 0.57444326, 0.5914578 ,\n",
       "                0.34524668, 0.9647702 , 0.18093961, 0.53742833, 0.32960073]]),\n",
       "        0,\n",
       "        0,\n",
       "        array([[0.44769043, 0.53991579, 0.57444326, 0.5914578 , 0.34524668,\n",
       "                0.9647702 , 0.18093961, 0.53742833, 0.32960073, 0.32959736]]),\n",
       "        False),\n",
       "       (array([[0.44769043, 0.53991579, 0.57444326, 0.5914578 , 0.34524668,\n",
       "                0.9647702 , 0.18093961, 0.53742833, 0.32960073, 0.32959736]]),\n",
       "        2,\n",
       "        0.720001220703125,\n",
       "        array([[0.53991579, 0.57444326, 0.5914578 , 0.34524668, 0.9647702 ,\n",
       "                0.18093961, 0.53742833, 0.32960073, 0.32959736, 0.39174039]]),\n",
       "        False),\n",
       "       (array([[0.53991579, 0.57444326, 0.5914578 , 0.34524668, 0.9647702 ,\n",
       "                0.18093961, 0.53742833, 0.32960073, 0.32959736, 0.39174039]]),\n",
       "        0,\n",
       "        0,\n",
       "        array([[0.57444326, 0.5914578 , 0.34524668, 0.9647702 , 0.18093961,\n",
       "                0.53742833, 0.32960073, 0.32959736, 0.39174039, 0.57444326]]),\n",
       "        False),\n",
       "       (array([[0.57444326, 0.5914578 , 0.34524668, 0.9647702 , 0.18093961,\n",
       "                0.53742833, 0.32960073, 0.32959736, 0.39174039, 0.57444326]]),\n",
       "        2,\n",
       "        0,\n",
       "        array([[0.5914578 , 0.34524668, 0.9647702 , 0.18093961, 0.53742833,\n",
       "                0.32960073, 0.32959736, 0.39174039, 0.57444326, 0.69635532]]),\n",
       "        False),\n",
       "       (array([[0.5914578 , 0.34524668, 0.9647702 , 0.18093961, 0.53742833,\n",
       "                0.32960073, 0.32959736, 0.39174039, 0.57444326, 0.69635532]]),\n",
       "        2,\n",
       "        1.220001220703125,\n",
       "        array([[0.34524668, 0.9647702 , 0.18093961, 0.53742833, 0.32960073,\n",
       "                0.32959736, 0.39174039, 0.57444326, 0.69635532, 0.52996284]]),\n",
       "        False),\n",
       "       (array([[0.34524668, 0.9647702 , 0.18093961, 0.53742833, 0.32960073,\n",
       "                0.32959736, 0.39174039, 0.57444326, 0.69635532, 0.52996284]]),\n",
       "        2,\n",
       "        0,\n",
       "        array([[0.9647702 , 0.18093961, 0.53742833, 0.32960073, 0.32959736,\n",
       "                0.39174039, 0.57444326, 0.69635532, 0.52996284, 0.28699909]]),\n",
       "        False),\n",
       "       (array([[0.9647702 , 0.18093961, 0.53742833, 0.32960073, 0.32959736,\n",
       "                0.39174039, 0.57444326, 0.69635532, 0.52996284, 0.28699909]]),\n",
       "        1,\n",
       "        0,\n",
       "        array([[0.18093961, 0.53742833, 0.32960073, 0.32959736, 0.39174039,\n",
       "                0.57444326, 0.69635532, 0.52996284, 0.28699909, 0.88594793]]),\n",
       "        False),\n",
       "       (array([[0.18093961, 0.53742833, 0.32960073, 0.32959736, 0.39174039,\n",
       "                0.57444326, 0.69635532, 0.52996284, 0.28699909, 0.88594793]]),\n",
       "        2,\n",
       "        2.0500030517578125,\n",
       "        array([[0.53742833, 0.32960073, 0.32959736, 0.39174039, 0.57444326,\n",
       "                0.69635532, 0.52996284, 0.28699909, 0.88594793, 0.38461595]]),\n",
       "        False)],\n",
       "      maxlen=2000)"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trader.memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'trader' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\jesiq\\github\\Material_tec\\Codigos\\RL con TensorFlow.ipynb Cell 9\u001b[0m line \u001b[0;36m1\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/jesiq/github/Material_tec/Codigos/RL%20con%20TensorFlow.ipynb#X11sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m trader\u001b[39m.\u001b[39mmemory[\u001b[39m0\u001b[39m][\u001b[39m0\u001b[39m] \u001b[39m# Primer state\u001b[39;00m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'trader' is not defined"
     ]
    }
   ],
   "source": [
    "trader.memory[0][0] # Primer state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/50 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    File \"c:\\Users\\jesiq\\anaconda3\\envs\\talib\\lib\\site-packages\\keras\\src\\engine\\training.py\", line 2416, in predict_function  *\n        return step_function(self, iterator)\n    File \"c:\\Users\\jesiq\\anaconda3\\envs\\talib\\lib\\site-packages\\keras\\src\\engine\\training.py\", line 2401, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"c:\\Users\\jesiq\\anaconda3\\envs\\talib\\lib\\site-packages\\keras\\src\\engine\\training.py\", line 2389, in run_step  **\n        outputs = model.predict_step(data)\n    File \"c:\\Users\\jesiq\\anaconda3\\envs\\talib\\lib\\site-packages\\keras\\src\\engine\\training.py\", line 2357, in predict_step\n        return self(x, training=False)\n    File \"c:\\Users\\jesiq\\anaconda3\\envs\\talib\\lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"c:\\Users\\jesiq\\anaconda3\\envs\\talib\\lib\\site-packages\\keras\\src\\engine\\input_spec.py\", line 298, in assert_input_compatibility\n        raise ValueError(\n\n    ValueError: Input 0 of layer \"sequential\" is incompatible with the layer: expected shape=(None, 10), found shape=(None, 1, 1, 10)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\jesiq\\github\\Material_tec\\Codigos\\RL con TensorFlow.ipynb Cell 11\u001b[0m line \u001b[0;36m5\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/jesiq/github/Material_tec/Codigos/RL%20con%20TensorFlow.ipynb#X13sZmlsZQ%3D%3D?line=48'>49</a>\u001b[0m   \u001b[39m# Chekc if we have more information in our memory than batch size\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/jesiq/github/Material_tec/Codigos/RL%20con%20TensorFlow.ipynb#X13sZmlsZQ%3D%3D?line=49'>50</a>\u001b[0m   \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(trader\u001b[39m.\u001b[39mmemory) \u001b[39m>\u001b[39m batch_size:\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/jesiq/github/Material_tec/Codigos/RL%20con%20TensorFlow.ipynb#X13sZmlsZQ%3D%3D?line=50'>51</a>\u001b[0m     trader\u001b[39m.\u001b[39;49mbatch_train(batch_size)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/jesiq/github/Material_tec/Codigos/RL%20con%20TensorFlow.ipynb#X13sZmlsZQ%3D%3D?line=52'>53</a>\u001b[0m \u001b[39m# Save the model every 10 episodes\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/jesiq/github/Material_tec/Codigos/RL%20con%20TensorFlow.ipynb#X13sZmlsZQ%3D%3D?line=53'>54</a>\u001b[0m   \u001b[39mif\u001b[39;00m episode \u001b[39m%\u001b[39m \u001b[39m10\u001b[39m \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n",
      "\u001b[1;32mc:\\Users\\jesiq\\github\\Material_tec\\Codigos\\RL con TensorFlow.ipynb Cell 11\u001b[0m line \u001b[0;36m7\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/jesiq/github/Material_tec/Codigos/RL%20con%20TensorFlow.ipynb#X13sZmlsZQ%3D%3D?line=70'>71</a>\u001b[0m \u001b[39m# Check that agent is not in terminal state\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/jesiq/github/Material_tec/Codigos/RL%20con%20TensorFlow.ipynb#X13sZmlsZQ%3D%3D?line=71'>72</a>\u001b[0m \u001b[39m# If not in terminal state calculate reward for actions that could be played\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/jesiq/github/Material_tec/Codigos/RL%20con%20TensorFlow.ipynb#X13sZmlsZQ%3D%3D?line=72'>73</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m done:\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/jesiq/github/Material_tec/Codigos/RL%20con%20TensorFlow.ipynb#X13sZmlsZQ%3D%3D?line=73'>74</a>\u001b[0m   \u001b[39m# Discounted total reward:\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/jesiq/github/Material_tec/Codigos/RL%20con%20TensorFlow.ipynb#X13sZmlsZQ%3D%3D?line=74'>75</a>\u001b[0m   reward \u001b[39m=\u001b[39m reward \u001b[39m+\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgamma \u001b[39m*\u001b[39m np\u001b[39m.\u001b[39mamax(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmodel\u001b[39m.\u001b[39;49mpredict(next_state)[\u001b[39m0\u001b[39m])        \n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/jesiq/github/Material_tec/Codigos/RL%20con%20TensorFlow.ipynb#X13sZmlsZQ%3D%3D?line=75'>76</a>\u001b[0m \u001b[39m# Target variable that is predicted by the model (action)\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/jesiq/github/Material_tec/Codigos/RL%20con%20TensorFlow.ipynb#X13sZmlsZQ%3D%3D?line=76'>77</a>\u001b[0m target \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel\u001b[39m.\u001b[39mpredict(state)\n",
      "File \u001b[1;32mc:\\Users\\jesiq\\anaconda3\\envs\\talib\\lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[39m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[39m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m     71\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32m~\\AppData\\Local\\Temp\\__autograph_generated_filegwgqqbid.py:15\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__predict_function\u001b[1;34m(iterator)\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m     14\u001b[0m     do_return \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m---> 15\u001b[0m     retval_ \u001b[39m=\u001b[39m ag__\u001b[39m.\u001b[39mconverted_call(ag__\u001b[39m.\u001b[39mld(step_function), (ag__\u001b[39m.\u001b[39mld(\u001b[39mself\u001b[39m), ag__\u001b[39m.\u001b[39mld(iterator)), \u001b[39mNone\u001b[39;00m, fscope)\n\u001b[0;32m     16\u001b[0m \u001b[39mexcept\u001b[39;00m:\n\u001b[0;32m     17\u001b[0m     do_return \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n",
      "\u001b[1;31mValueError\u001b[0m: in user code:\n\n    File \"c:\\Users\\jesiq\\anaconda3\\envs\\talib\\lib\\site-packages\\keras\\src\\engine\\training.py\", line 2416, in predict_function  *\n        return step_function(self, iterator)\n    File \"c:\\Users\\jesiq\\anaconda3\\envs\\talib\\lib\\site-packages\\keras\\src\\engine\\training.py\", line 2401, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"c:\\Users\\jesiq\\anaconda3\\envs\\talib\\lib\\site-packages\\keras\\src\\engine\\training.py\", line 2389, in run_step  **\n        outputs = model.predict_step(data)\n    File \"c:\\Users\\jesiq\\anaconda3\\envs\\talib\\lib\\site-packages\\keras\\src\\engine\\training.py\", line 2357, in predict_step\n        return self(x, training=False)\n    File \"c:\\Users\\jesiq\\anaconda3\\envs\\talib\\lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"c:\\Users\\jesiq\\anaconda3\\envs\\talib\\lib\\site-packages\\keras\\src\\engine\\input_spec.py\", line 298, in assert_input_compatibility\n        raise ValueError(\n\n    ValueError: Input 0 of layer \"sequential\" is incompatible with the layer: expected shape=(None, 10), found shape=(None, 1, 1, 10)\n"
     ]
    }
   ],
   "source": [
    "episode = 1\n",
    "state = state_indicador_creator(data, timestep=0, window_size=window_size)\n",
    "total_profit = []\n",
    "trader.inventory = []\n",
    "\n",
    "\n",
    "for t in tqdm(range(50)):\n",
    "    action = trader.trade(state)\n",
    "\n",
    "        # Use action to get to next state(t+)\n",
    "    next_state = state_indicador_creator(data=data, timestep=(t + 1), window_size=(9 + 1))\n",
    "    # As we did not calculate anything up to this point reward is 0\n",
    "    reward = 0\n",
    "    \n",
    "    if action == 1: #Buying\n",
    "      # Put buyed stock to inventory to trade with\n",
    "      trader.inventory.append(data.iloc[t])\n",
    "      print(\"AI Trader bought: \", stocks_price_format(data[t]))\n",
    "      \n",
    "    # To sell we need to have something in inventory  \n",
    "    elif action == 2 and len(trader.inventory) > 0: #Selling\n",
    "      # Check buy price, pop removes first value from list\n",
    "      buy_price = trader.inventory.pop(0)\n",
    "      \n",
    "      # If we gain money (current price - buy price) we have reward \n",
    "      #    if we lost money then reward is 0\n",
    "      reward = max(data.iloc[t] - buy_price, 0)\n",
    "      total_profit += data[t] - buy_price\n",
    "      print(\"AI Trader sold: \", stocks_price_format(data[t]), \" Profit: \" + stocks_price_format(data[t] - buy_price) )\n",
    "      \n",
    "    # if t is last sample in our dateset we are done\n",
    "    #     we do not have any steps to perform in current episode\n",
    "    if t == data_samples - 1:\n",
    "      done = True\n",
    "    else:\n",
    "      done = False\n",
    "    \n",
    "    # Append all data to trader-agent memory, experience buffer\n",
    "    trader.memory.append((state, action, reward, next_state, done))\n",
    "    \n",
    "    # change state to next state, so we are done with an episode\n",
    "    state = next_state\n",
    "    \n",
    "    if done:\n",
    "      print(\"########################\")\n",
    "      print(\"TOTAL PROFIT: {}\".format(total_profit))\n",
    "      print(\"########################\")\n",
    "    \n",
    "    # Chekc if we have more information in our memory than batch size\n",
    "    if len(trader.memory) > batch_size:\n",
    "      trader.batch_train(batch_size)\n",
    "  \n",
    "  # Save the model every 10 episodes\n",
    "    if episode % 10 == 0:\n",
    "       trader.model.save(\"ai_trader_{}.h5\".format(episode))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    File \"c:\\Users\\jesiq\\anaconda3\\envs\\talib\\lib\\site-packages\\keras\\src\\engine\\training.py\", line 2416, in predict_function  *\n        return step_function(self, iterator)\n    File \"c:\\Users\\jesiq\\anaconda3\\envs\\talib\\lib\\site-packages\\keras\\src\\engine\\training.py\", line 2401, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"c:\\Users\\jesiq\\anaconda3\\envs\\talib\\lib\\site-packages\\keras\\src\\engine\\training.py\", line 2389, in run_step  **\n        outputs = model.predict_step(data)\n    File \"c:\\Users\\jesiq\\anaconda3\\envs\\talib\\lib\\site-packages\\keras\\src\\engine\\training.py\", line 2357, in predict_step\n        return self(x, training=False)\n    File \"c:\\Users\\jesiq\\anaconda3\\envs\\talib\\lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"c:\\Users\\jesiq\\anaconda3\\envs\\talib\\lib\\site-packages\\keras\\src\\engine\\input_spec.py\", line 298, in assert_input_compatibility\n        raise ValueError(\n\n    ValueError: Input 0 of layer \"sequential\" is incompatible with the layer: expected shape=(None, 10), found shape=(None, 1, 1, 10)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\jesiq\\github\\Material_tec\\Codigos\\RL con TensorFlow.ipynb Cell 12\u001b[0m line \u001b[0;36m1\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/jesiq/github/Material_tec/Codigos/RL%20con%20TensorFlow.ipynb#X14sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m reward \u001b[39m=\u001b[39m reward \u001b[39m+\u001b[39m trader\u001b[39m.\u001b[39mgamma \u001b[39m*\u001b[39m np\u001b[39m.\u001b[39mamax(trader\u001b[39m.\u001b[39;49mmodel\u001b[39m.\u001b[39;49mpredict(next_state)[\u001b[39m0\u001b[39m]) \n",
      "File \u001b[1;32mc:\\Users\\jesiq\\anaconda3\\envs\\talib\\lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[39m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[39m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m     71\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32m~\\AppData\\Local\\Temp\\__autograph_generated_filegwgqqbid.py:15\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__predict_function\u001b[1;34m(iterator)\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m     14\u001b[0m     do_return \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m---> 15\u001b[0m     retval_ \u001b[39m=\u001b[39m ag__\u001b[39m.\u001b[39mconverted_call(ag__\u001b[39m.\u001b[39mld(step_function), (ag__\u001b[39m.\u001b[39mld(\u001b[39mself\u001b[39m), ag__\u001b[39m.\u001b[39mld(iterator)), \u001b[39mNone\u001b[39;00m, fscope)\n\u001b[0;32m     16\u001b[0m \u001b[39mexcept\u001b[39;00m:\n\u001b[0;32m     17\u001b[0m     do_return \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n",
      "\u001b[1;31mValueError\u001b[0m: in user code:\n\n    File \"c:\\Users\\jesiq\\anaconda3\\envs\\talib\\lib\\site-packages\\keras\\src\\engine\\training.py\", line 2416, in predict_function  *\n        return step_function(self, iterator)\n    File \"c:\\Users\\jesiq\\anaconda3\\envs\\talib\\lib\\site-packages\\keras\\src\\engine\\training.py\", line 2401, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"c:\\Users\\jesiq\\anaconda3\\envs\\talib\\lib\\site-packages\\keras\\src\\engine\\training.py\", line 2389, in run_step  **\n        outputs = model.predict_step(data)\n    File \"c:\\Users\\jesiq\\anaconda3\\envs\\talib\\lib\\site-packages\\keras\\src\\engine\\training.py\", line 2357, in predict_step\n        return self(x, training=False)\n    File \"c:\\Users\\jesiq\\anaconda3\\envs\\talib\\lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"c:\\Users\\jesiq\\anaconda3\\envs\\talib\\lib\\site-packages\\keras\\src\\engine\\input_spec.py\", line 298, in assert_input_compatibility\n        raise ValueError(\n\n    ValueError: Input 0 of layer \"sequential\" is incompatible with the layer: expected shape=(None, 10), found shape=(None, 1, 1, 10)\n"
     ]
    }
   ],
   "source": [
    "reward = reward + trader.gamma * np.amax(trader.model.predict(next_state)[0]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    File \"c:\\Users\\jesiq\\anaconda3\\envs\\talib\\lib\\site-packages\\keras\\src\\engine\\training.py\", line 2416, in predict_function  *\n        return step_function(self, iterator)\n    File \"c:\\Users\\jesiq\\anaconda3\\envs\\talib\\lib\\site-packages\\keras\\src\\engine\\training.py\", line 2401, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"c:\\Users\\jesiq\\anaconda3\\envs\\talib\\lib\\site-packages\\keras\\src\\engine\\training.py\", line 2389, in run_step  **\n        outputs = model.predict_step(data)\n    File \"c:\\Users\\jesiq\\anaconda3\\envs\\talib\\lib\\site-packages\\keras\\src\\engine\\training.py\", line 2357, in predict_step\n        return self(x, training=False)\n    File \"c:\\Users\\jesiq\\anaconda3\\envs\\talib\\lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"c:\\Users\\jesiq\\anaconda3\\envs\\talib\\lib\\site-packages\\keras\\src\\engine\\input_spec.py\", line 298, in assert_input_compatibility\n        raise ValueError(\n\n    ValueError: Input 0 of layer \"sequential\" is incompatible with the layer: expected shape=(None, 10), found shape=(None, 1, 1, 10)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\jesiq\\github\\Material_tec\\Codigos\\RL con TensorFlow.ipynb Cell 13\u001b[0m line \u001b[0;36m1\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/jesiq/github/Material_tec/Codigos/RL%20con%20TensorFlow.ipynb#X15sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m trader\u001b[39m.\u001b[39;49mmodel\u001b[39m.\u001b[39;49mpredict(next_state)\n",
      "File \u001b[1;32mc:\\Users\\jesiq\\anaconda3\\envs\\talib\\lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[39m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[39m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m     71\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32m~\\AppData\\Local\\Temp\\__autograph_generated_filegwgqqbid.py:15\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__predict_function\u001b[1;34m(iterator)\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m     14\u001b[0m     do_return \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m---> 15\u001b[0m     retval_ \u001b[39m=\u001b[39m ag__\u001b[39m.\u001b[39mconverted_call(ag__\u001b[39m.\u001b[39mld(step_function), (ag__\u001b[39m.\u001b[39mld(\u001b[39mself\u001b[39m), ag__\u001b[39m.\u001b[39mld(iterator)), \u001b[39mNone\u001b[39;00m, fscope)\n\u001b[0;32m     16\u001b[0m \u001b[39mexcept\u001b[39;00m:\n\u001b[0;32m     17\u001b[0m     do_return \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n",
      "\u001b[1;31mValueError\u001b[0m: in user code:\n\n    File \"c:\\Users\\jesiq\\anaconda3\\envs\\talib\\lib\\site-packages\\keras\\src\\engine\\training.py\", line 2416, in predict_function  *\n        return step_function(self, iterator)\n    File \"c:\\Users\\jesiq\\anaconda3\\envs\\talib\\lib\\site-packages\\keras\\src\\engine\\training.py\", line 2401, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"c:\\Users\\jesiq\\anaconda3\\envs\\talib\\lib\\site-packages\\keras\\src\\engine\\training.py\", line 2389, in run_step  **\n        outputs = model.predict_step(data)\n    File \"c:\\Users\\jesiq\\anaconda3\\envs\\talib\\lib\\site-packages\\keras\\src\\engine\\training.py\", line 2357, in predict_step\n        return self(x, training=False)\n    File \"c:\\Users\\jesiq\\anaconda3\\envs\\talib\\lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"c:\\Users\\jesiq\\anaconda3\\envs\\talib\\lib\\site-packages\\keras\\src\\engine\\input_spec.py\", line 298, in assert_input_compatibility\n        raise ValueError(\n\n    ValueError: Input 0 of layer \"sequential\" is incompatible with the layer: expected shape=(None, 10), found shape=(None, 1, 1, 10)\n"
     ]
    }
   ],
   "source": [
    "trader.model.predict(next_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.339997000000011"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "226.580002 - 225.240005"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.792489448091031"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#def sigmoid(x):\n",
    "  #return\n",
    "1 / (1 + math.exp(-1.339997000000011))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.7957598 , 0.71299779, 0.77902779, 0.7170738 , 0.77206376,\n",
       "        0.45016676, 0.5914578 , 0.80218534, 0.44769043, 0.53991579]])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "56"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(trader.memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "deque([(array([[0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5]]),\n",
       "        1,\n",
       "        0,\n",
       "        array([[0.5       , 0.5       , 0.5       , 0.5       , 0.5       ,\n",
       "                0.5       , 0.5       , 0.5       , 0.5       , 0.79248934]]),\n",
       "        False),\n",
       "       (array([[0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5]]),\n",
       "        2,\n",
       "        0,\n",
       "        array([[0.5       , 0.5       , 0.5       , 0.5       , 0.5       ,\n",
       "                0.5       , 0.5       , 0.5       , 0.5       , 0.79248934]]),\n",
       "        False),\n",
       "       (array([[0.5       , 0.5       , 0.5       , 0.5       , 0.5       ,\n",
       "                0.5       , 0.5       , 0.5       , 0.5       , 0.79248934]]),\n",
       "        1,\n",
       "        0,\n",
       "        array([[0.5       , 0.5       , 0.5       , 0.5       , 0.5       ,\n",
       "                0.5       , 0.5       , 0.5       , 0.79248934, 0.45511914]]),\n",
       "        False),\n",
       "       (array([[0.5       , 0.5       , 0.5       , 0.5       , 0.5       ,\n",
       "                0.5       , 0.5       , 0.5       , 0.79248934, 0.45511914]]),\n",
       "        0,\n",
       "        0,\n",
       "        array([[0.5       , 0.5       , 0.5       , 0.5       , 0.5       ,\n",
       "                0.5       , 0.5       , 0.79248934, 0.45511914, 0.69211224]]),\n",
       "        False),\n",
       "       (array([[0.5       , 0.5       , 0.5       , 0.5       , 0.5       ,\n",
       "                0.5       , 0.5       , 0.79248934, 0.45511914, 0.69211224]]),\n",
       "        2,\n",
       "        0.6300048828125,\n",
       "        array([[0.5       , 0.5       , 0.5       , 0.5       , 0.5       ,\n",
       "                0.5       , 0.79248934, 0.45511914, 0.69211224, 0.3208213 ]]),\n",
       "        False),\n",
       "       (array([[0.5       , 0.5       , 0.5       , 0.5       , 0.5       ,\n",
       "                0.5       , 0.79248934, 0.45511914, 0.69211224, 0.3208213 ]]),\n",
       "        1,\n",
       "        0,\n",
       "        array([[0.5       , 0.5       , 0.5       , 0.5       , 0.5       ,\n",
       "                0.79248934, 0.45511914, 0.69211224, 0.3208213 , 0.5       ]]),\n",
       "        False),\n",
       "       (array([[0.5       , 0.5       , 0.5       , 0.5       , 0.5       ,\n",
       "                0.79248934, 0.45511914, 0.69211224, 0.3208213 , 0.5       ]]),\n",
       "        2,\n",
       "        0.0,\n",
       "        array([[0.5       , 0.5       , 0.5       , 0.5       , 0.79248934,\n",
       "                0.45511914, 0.69211224, 0.3208213 , 0.5       , 0.65475332]]),\n",
       "        False),\n",
       "       (array([[0.5       , 0.5       , 0.5       , 0.5       , 0.79248934,\n",
       "                0.45511914, 0.69211224, 0.3208213 , 0.5       , 0.65475332]]),\n",
       "        1,\n",
       "        0,\n",
       "        array([[0.5       , 0.5       , 0.5       , 0.79248934, 0.45511914,\n",
       "                0.69211224, 0.3208213 , 0.5       , 0.65475332, 0.36123513]]),\n",
       "        False),\n",
       "       (array([[0.5       , 0.5       , 0.5       , 0.79248934, 0.45511914,\n",
       "                0.69211224, 0.3208213 , 0.5       , 0.65475332, 0.36123513]]),\n",
       "        2,\n",
       "        0,\n",
       "        array([[0.5       , 0.5       , 0.79248934, 0.45511914, 0.69211224,\n",
       "                0.3208213 , 0.5       , 0.65475332, 0.36123513, 0.62714877]]),\n",
       "        False),\n",
       "       (array([[0.5       , 0.5       , 0.79248934, 0.45511914, 0.69211224,\n",
       "                0.3208213 , 0.5       , 0.65475332, 0.36123513, 0.62714877]]),\n",
       "        1,\n",
       "        0,\n",
       "        array([[0.5       , 0.79248934, 0.45511914, 0.69211224, 0.3208213 ,\n",
       "                0.5       , 0.65475332, 0.36123513, 0.62714877, 0.31002487]]),\n",
       "        False),\n",
       "       (array([[0.5       , 0.79248934, 0.45511914, 0.69211224, 0.3208213 ,\n",
       "                0.5       , 0.65475332, 0.36123513, 0.62714877, 0.31002487]]),\n",
       "        2,\n",
       "        0,\n",
       "        array([[0.79248934, 0.45511914, 0.69211224, 0.3208213 , 0.5       ,\n",
       "                0.65475332, 0.36123513, 0.62714877, 0.31002487, 0.62245933]]),\n",
       "        False),\n",
       "       (array([[0.79248934, 0.45511914, 0.69211224, 0.3208213 , 0.5       ,\n",
       "                0.65475332, 0.36123513, 0.62714877, 0.31002487, 0.62245933]]),\n",
       "        0,\n",
       "        0,\n",
       "        array([[0.45511914, 0.69211224, 0.3208213 , 0.5       , 0.65475332,\n",
       "                0.36123513, 0.62714877, 0.31002487, 0.62245933, 0.30153556]]),\n",
       "        False),\n",
       "       (array([[0.45511914, 0.69211224, 0.3208213 , 0.5       , 0.65475332,\n",
       "                0.36123513, 0.62714877, 0.31002487, 0.62245933, 0.30153556]]),\n",
       "        0,\n",
       "        0,\n",
       "        array([[0.69211224, 0.3208213 , 0.5       , 0.65475332, 0.36123513,\n",
       "                0.62714877, 0.31002487, 0.62245933, 0.30153556, 0.69635532]]),\n",
       "        False),\n",
       "       (array([[0.69211224, 0.3208213 , 0.5       , 0.65475332, 0.36123513,\n",
       "                0.62714877, 0.31002487, 0.62245933, 0.30153556, 0.69635532]]),\n",
       "        2,\n",
       "        0,\n",
       "        array([[0.3208213 , 0.5       , 0.65475332, 0.36123513, 0.62714877,\n",
       "                0.31002487, 0.62245933, 0.30153556, 0.69635532, 0.35663219]]),\n",
       "        False),\n",
       "       (array([[0.3208213 , 0.5       , 0.65475332, 0.36123513, 0.62714877,\n",
       "                0.31002487, 0.62245933, 0.30153556, 0.69635532, 0.35663219]]),\n",
       "        2,\n",
       "        0,\n",
       "        array([[0.5       , 0.65475332, 0.36123513, 0.62714877, 0.31002487,\n",
       "                0.62245933, 0.30153556, 0.69635532, 0.35663219, 0.81000031]]),\n",
       "        False),\n",
       "       (array([[0.5       , 0.65475332, 0.36123513, 0.62714877, 0.31002487,\n",
       "                0.62245933, 0.30153556, 0.69635532, 0.35663219, 0.81000031]]),\n",
       "        0,\n",
       "        0,\n",
       "        array([[0.65475332, 0.36123513, 0.62714877, 0.31002487, 0.62245933,\n",
       "                0.30153556, 0.69635532, 0.35663219, 0.81000031, 0.87761124]]),\n",
       "        False),\n",
       "       (array([[0.65475332, 0.36123513, 0.62714877, 0.31002487, 0.62245933,\n",
       "                0.30153556, 0.69635532, 0.35663219, 0.81000031, 0.87761124]]),\n",
       "        1,\n",
       "        0,\n",
       "        array([[0.36123513, 0.62714877, 0.31002487, 0.62245933, 0.30153556,\n",
       "                0.69635532, 0.35663219, 0.81000031, 0.87761124, 0.440285  ]]),\n",
       "        False),\n",
       "       (array([[0.36123513, 0.62714877, 0.31002487, 0.62245933, 0.30153556,\n",
       "                0.69635532, 0.35663219, 0.81000031, 0.87761124, 0.440285  ]]),\n",
       "        2,\n",
       "        0,\n",
       "        array([[0.62714877, 0.31002487, 0.62245933, 0.30153556, 0.69635532,\n",
       "                0.35663219, 0.81000031, 0.87761124, 0.440285  , 0.41095942]]),\n",
       "        False),\n",
       "       (array([[0.62714877, 0.31002487, 0.62245933, 0.30153556, 0.69635532,\n",
       "                0.35663219, 0.81000031, 0.87761124, 0.440285  , 0.41095942]]),\n",
       "        2,\n",
       "        0,\n",
       "        array([[0.31002487, 0.62245933, 0.30153556, 0.69635532, 0.35663219,\n",
       "                0.81000031, 0.87761124, 0.440285  , 0.41095942, 0.19466187]]),\n",
       "        False),\n",
       "       (array([[0.31002487, 0.62245933, 0.30153556, 0.69635532, 0.35663219,\n",
       "                0.81000031, 0.87761124, 0.440285  , 0.41095942, 0.19466187]]),\n",
       "        0,\n",
       "        0,\n",
       "        array([[0.62245933, 0.30153556, 0.69635532, 0.35663219, 0.81000031,\n",
       "                0.87761124, 0.440285  , 0.41095942, 0.19466187, 0.4949991 ]]),\n",
       "        False),\n",
       "       (array([[0.62245933, 0.30153556, 0.69635532, 0.35663219, 0.81000031,\n",
       "                0.87761124, 0.440285  , 0.41095942, 0.19466187, 0.4949991 ]]),\n",
       "        0,\n",
       "        0,\n",
       "        array([[0.30153556, 0.69635532, 0.35663219, 0.81000031, 0.87761124,\n",
       "                0.440285  , 0.41095942, 0.19466187, 0.4949991 , 0.52248391]]),\n",
       "        False),\n",
       "       (array([[0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5]]),\n",
       "        0,\n",
       "        0,\n",
       "        array([[0.5       , 0.5       , 0.5       , 0.5       , 0.5       ,\n",
       "                0.5       , 0.5       , 0.5       , 0.5       , 0.79248934]]),\n",
       "        False),\n",
       "       (array([[0.5       , 0.5       , 0.5       , 0.5       , 0.5       ,\n",
       "                0.5       , 0.5       , 0.5       , 0.5       , 0.79248934]]),\n",
       "        0,\n",
       "        0,\n",
       "        array([[0.5       , 0.5       , 0.5       , 0.5       , 0.5       ,\n",
       "                0.5       , 0.5       , 0.5       , 0.79248934, 0.45511914]]),\n",
       "        False),\n",
       "       (array([[0.5       , 0.5       , 0.5       , 0.5       , 0.5       ,\n",
       "                0.5       , 0.5       , 0.5       , 0.79248934, 0.45511914]]),\n",
       "        0,\n",
       "        0,\n",
       "        array([[0.5       , 0.5       , 0.5       , 0.5       , 0.5       ,\n",
       "                0.5       , 0.5       , 0.79248934, 0.45511914, 0.69211224]]),\n",
       "        False),\n",
       "       (array([[0.5       , 0.5       , 0.5       , 0.5       , 0.5       ,\n",
       "                0.5       , 0.5       , 0.79248934, 0.45511914, 0.69211224]]),\n",
       "        2,\n",
       "        0,\n",
       "        array([[0.5       , 0.5       , 0.5       , 0.5       , 0.5       ,\n",
       "                0.5       , 0.79248934, 0.45511914, 0.69211224, 0.3208213 ]]),\n",
       "        False),\n",
       "       (array([[0.5       , 0.5       , 0.5       , 0.5       , 0.5       ,\n",
       "                0.5       , 0.79248934, 0.45511914, 0.69211224, 0.3208213 ]]),\n",
       "        1,\n",
       "        0,\n",
       "        array([[0.5       , 0.5       , 0.5       , 0.5       , 0.5       ,\n",
       "                0.79248934, 0.45511914, 0.69211224, 0.3208213 , 0.5       ]]),\n",
       "        False),\n",
       "       (array([[0.5       , 0.5       , 0.5       , 0.5       , 0.5       ,\n",
       "                0.79248934, 0.45511914, 0.69211224, 0.3208213 , 0.5       ]]),\n",
       "        1,\n",
       "        0,\n",
       "        array([[0.5       , 0.5       , 0.5       , 0.5       , 0.79248934,\n",
       "                0.45511914, 0.69211224, 0.3208213 , 0.5       , 0.65475332]]),\n",
       "        False),\n",
       "       (array([[0.5       , 0.5       , 0.5       , 0.5       , 0.79248934,\n",
       "                0.45511914, 0.69211224, 0.3208213 , 0.5       , 0.65475332]]),\n",
       "        0,\n",
       "        0,\n",
       "        array([[0.5       , 0.5       , 0.5       , 0.79248934, 0.45511914,\n",
       "                0.69211224, 0.3208213 , 0.5       , 0.65475332, 0.36123513]]),\n",
       "        False),\n",
       "       (array([[0.5       , 0.5       , 0.5       , 0.79248934, 0.45511914,\n",
       "                0.69211224, 0.3208213 , 0.5       , 0.65475332, 0.36123513]]),\n",
       "        1,\n",
       "        0,\n",
       "        array([[0.5       , 0.5       , 0.79248934, 0.45511914, 0.69211224,\n",
       "                0.3208213 , 0.5       , 0.65475332, 0.36123513, 0.62714877]]),\n",
       "        False),\n",
       "       (array([[0.5       , 0.5       , 0.79248934, 0.45511914, 0.69211224,\n",
       "                0.3208213 , 0.5       , 0.65475332, 0.36123513, 0.62714877]]),\n",
       "        2,\n",
       "        0.589996337890625,\n",
       "        array([[0.5       , 0.79248934, 0.45511914, 0.69211224, 0.3208213 ,\n",
       "                0.5       , 0.65475332, 0.36123513, 0.62714877, 0.31002487]]),\n",
       "        False),\n",
       "       (array([[0.5       , 0.79248934, 0.45511914, 0.69211224, 0.3208213 ,\n",
       "                0.5       , 0.65475332, 0.36123513, 0.62714877, 0.31002487]]),\n",
       "        1,\n",
       "        0,\n",
       "        array([[0.79248934, 0.45511914, 0.69211224, 0.3208213 , 0.5       ,\n",
       "                0.65475332, 0.36123513, 0.62714877, 0.31002487, 0.62245933]]),\n",
       "        False),\n",
       "       (array([[0.79248934, 0.45511914, 0.69211224, 0.3208213 , 0.5       ,\n",
       "                0.65475332, 0.36123513, 0.62714877, 0.31002487, 0.62245933]]),\n",
       "        1,\n",
       "        0,\n",
       "        array([[0.45511914, 0.69211224, 0.3208213 , 0.5       , 0.65475332,\n",
       "                0.36123513, 0.62714877, 0.31002487, 0.62245933, 0.30153556]]),\n",
       "        False),\n",
       "       (array([[0.45511914, 0.69211224, 0.3208213 , 0.5       , 0.65475332,\n",
       "                0.36123513, 0.62714877, 0.31002487, 0.62245933, 0.30153556]]),\n",
       "        1,\n",
       "        0,\n",
       "        array([[0.69211224, 0.3208213 , 0.5       , 0.65475332, 0.36123513,\n",
       "                0.62714877, 0.31002487, 0.62245933, 0.30153556, 0.69635532]]),\n",
       "        False),\n",
       "       (array([[0.69211224, 0.3208213 , 0.5       , 0.65475332, 0.36123513,\n",
       "                0.62714877, 0.31002487, 0.62245933, 0.30153556, 0.69635532]]),\n",
       "        1,\n",
       "        0,\n",
       "        array([[0.3208213 , 0.5       , 0.65475332, 0.36123513, 0.62714877,\n",
       "                0.31002487, 0.62245933, 0.30153556, 0.69635532, 0.35663219]]),\n",
       "        False),\n",
       "       (array([[0.3208213 , 0.5       , 0.65475332, 0.36123513, 0.62714877,\n",
       "                0.31002487, 0.62245933, 0.30153556, 0.69635532, 0.35663219]]),\n",
       "        0,\n",
       "        0,\n",
       "        array([[0.5       , 0.65475332, 0.36123513, 0.62714877, 0.31002487,\n",
       "                0.62245933, 0.30153556, 0.69635532, 0.35663219, 0.81000031]]),\n",
       "        False),\n",
       "       (array([[0.5       , 0.65475332, 0.36123513, 0.62714877, 0.31002487,\n",
       "                0.62245933, 0.30153556, 0.69635532, 0.35663219, 0.81000031]]),\n",
       "        0,\n",
       "        0,\n",
       "        array([[0.65475332, 0.36123513, 0.62714877, 0.31002487, 0.62245933,\n",
       "                0.30153556, 0.69635532, 0.35663219, 0.81000031, 0.87761124]]),\n",
       "        False),\n",
       "       (array([[0.65475332, 0.36123513, 0.62714877, 0.31002487, 0.62245933,\n",
       "                0.30153556, 0.69635532, 0.35663219, 0.81000031, 0.87761124]]),\n",
       "        0,\n",
       "        0,\n",
       "        array([[0.36123513, 0.62714877, 0.31002487, 0.62245933, 0.30153556,\n",
       "                0.69635532, 0.35663219, 0.81000031, 0.87761124, 0.440285  ]]),\n",
       "        False),\n",
       "       (array([[0.36123513, 0.62714877, 0.31002487, 0.62245933, 0.30153556,\n",
       "                0.69635532, 0.35663219, 0.81000031, 0.87761124, 0.440285  ]]),\n",
       "        0,\n",
       "        0,\n",
       "        array([[0.62714877, 0.31002487, 0.62245933, 0.30153556, 0.69635532,\n",
       "                0.35663219, 0.81000031, 0.87761124, 0.440285  , 0.41095942]]),\n",
       "        False),\n",
       "       (array([[0.62714877, 0.31002487, 0.62245933, 0.30153556, 0.69635532,\n",
       "                0.35663219, 0.81000031, 0.87761124, 0.440285  , 0.41095942]]),\n",
       "        2,\n",
       "        2.5099945068359375,\n",
       "        array([[0.31002487, 0.62245933, 0.30153556, 0.69635532, 0.35663219,\n",
       "                0.81000031, 0.87761124, 0.440285  , 0.41095942, 0.19466187]]),\n",
       "        False),\n",
       "       (array([[0.31002487, 0.62245933, 0.30153556, 0.69635532, 0.35663219,\n",
       "                0.81000031, 0.87761124, 0.440285  , 0.41095942, 0.19466187]]),\n",
       "        1,\n",
       "        0,\n",
       "        array([[0.62245933, 0.30153556, 0.69635532, 0.35663219, 0.81000031,\n",
       "                0.87761124, 0.440285  , 0.41095942, 0.19466187, 0.4949991 ]]),\n",
       "        False),\n",
       "       (array([[0.62245933, 0.30153556, 0.69635532, 0.35663219, 0.81000031,\n",
       "                0.87761124, 0.440285  , 0.41095942, 0.19466187, 0.4949991 ]]),\n",
       "        1,\n",
       "        0,\n",
       "        array([[0.30153556, 0.69635532, 0.35663219, 0.81000031, 0.87761124,\n",
       "                0.440285  , 0.41095942, 0.19466187, 0.4949991 , 0.52248391]]),\n",
       "        False),\n",
       "       (array([[0.30153556, 0.69635532, 0.35663219, 0.81000031, 0.87761124,\n",
       "                0.440285  , 0.41095942, 0.19466187, 0.4949991 , 0.52248391]]),\n",
       "        1,\n",
       "        0,\n",
       "        array([[0.69635532, 0.35663219, 0.81000031, 0.87761124, 0.440285  ,\n",
       "                0.41095942, 0.19466187, 0.4949991 , 0.52248391, 0.53743212]]),\n",
       "        False),\n",
       "       (array([[0.69635532, 0.35663219, 0.81000031, 0.87761124, 0.440285  ,\n",
       "                0.41095942, 0.19466187, 0.4949991 , 0.52248391, 0.53743212]]),\n",
       "        1,\n",
       "        0,\n",
       "        array([[0.35663219, 0.81000031, 0.87761124, 0.440285  , 0.41095942,\n",
       "                0.19466187, 0.4949991 , 0.52248391, 0.53743212, 0.82778248]]),\n",
       "        False),\n",
       "       (array([[0.35663219, 0.81000031, 0.87761124, 0.440285  , 0.41095942,\n",
       "                0.19466187, 0.4949991 , 0.52248391, 0.53743212, 0.82778248]]),\n",
       "        0,\n",
       "        0,\n",
       "        array([[0.81000031, 0.87761124, 0.440285  , 0.41095942, 0.19466187,\n",
       "                0.4949991 , 0.52248391, 0.53743212, 0.82778248, 0.39891124]]),\n",
       "        False),\n",
       "       (array([[0.81000031, 0.87761124, 0.440285  , 0.41095942, 0.19466187,\n",
       "                0.4949991 , 0.52248391, 0.53743212, 0.82778248, 0.39891124]]),\n",
       "        2,\n",
       "        2.399993896484375,\n",
       "        array([[0.87761124, 0.440285  , 0.41095942, 0.19466187, 0.4949991 ,\n",
       "                0.52248391, 0.53743212, 0.82778248, 0.39891124, 0.50250242]]),\n",
       "        False),\n",
       "       (array([[0.87761124, 0.440285  , 0.41095942, 0.19466187, 0.4949991 ,\n",
       "                0.52248391, 0.53743212, 0.82778248, 0.39891124, 0.50250242]]),\n",
       "        1,\n",
       "        0,\n",
       "        array([[0.440285  , 0.41095942, 0.19466187, 0.4949991 , 0.52248391,\n",
       "                0.53743212, 0.82778248, 0.39891124, 0.50250242, 0.57444326]]),\n",
       "        False),\n",
       "       (array([[0.440285  , 0.41095942, 0.19466187, 0.4949991 , 0.52248391,\n",
       "                0.53743212, 0.82778248, 0.39891124, 0.50250242, 0.57444326]]),\n",
       "        1,\n",
       "        0,\n",
       "        array([[0.41095942, 0.19466187, 0.4949991 , 0.52248391, 0.53743212,\n",
       "                0.82778248, 0.39891124, 0.50250242, 0.57444326, 0.7957598 ]]),\n",
       "        False),\n",
       "       (array([[0.41095942, 0.19466187, 0.4949991 , 0.52248391, 0.53743212,\n",
       "                0.82778248, 0.39891124, 0.50250242, 0.57444326, 0.7957598 ]]),\n",
       "        2,\n",
       "        4.350006103515625,\n",
       "        array([[0.19466187, 0.4949991 , 0.52248391, 0.53743212, 0.82778248,\n",
       "                0.39891124, 0.50250242, 0.57444326, 0.7957598 , 0.71299779]]),\n",
       "        False),\n",
       "       (array([[0.19466187, 0.4949991 , 0.52248391, 0.53743212, 0.82778248,\n",
       "                0.39891124, 0.50250242, 0.57444326, 0.7957598 , 0.71299779]]),\n",
       "        2,\n",
       "        4.7599945068359375,\n",
       "        array([[0.4949991 , 0.52248391, 0.53743212, 0.82778248, 0.39891124,\n",
       "                0.50250242, 0.57444326, 0.7957598 , 0.71299779, 0.77902779]]),\n",
       "        False),\n",
       "       (array([[0.4949991 , 0.52248391, 0.53743212, 0.82778248, 0.39891124,\n",
       "                0.50250242, 0.57444326, 0.7957598 , 0.71299779, 0.77902779]]),\n",
       "        2,\n",
       "        6.8600006103515625,\n",
       "        array([[0.52248391, 0.53743212, 0.82778248, 0.39891124, 0.50250242,\n",
       "                0.57444326, 0.7957598 , 0.71299779, 0.77902779, 0.7170738 ]]),\n",
       "        False),\n",
       "       (array([[0.52248391, 0.53743212, 0.82778248, 0.39891124, 0.50250242,\n",
       "                0.57444326, 0.7957598 , 0.71299779, 0.77902779, 0.7170738 ]]),\n",
       "        1,\n",
       "        0,\n",
       "        array([[0.53743212, 0.82778248, 0.39891124, 0.50250242, 0.57444326,\n",
       "                0.7957598 , 0.71299779, 0.77902779, 0.7170738 , 0.77206376]]),\n",
       "        False),\n",
       "       (array([[0.53743212, 0.82778248, 0.39891124, 0.50250242, 0.57444326,\n",
       "                0.7957598 , 0.71299779, 0.77902779, 0.7170738 , 0.77206376]]),\n",
       "        0,\n",
       "        0,\n",
       "        array([[0.82778248, 0.39891124, 0.50250242, 0.57444326, 0.7957598 ,\n",
       "                0.71299779, 0.77902779, 0.7170738 , 0.77206376, 0.45016676]]),\n",
       "        False),\n",
       "       (array([[0.82778248, 0.39891124, 0.50250242, 0.57444326, 0.7957598 ,\n",
       "                0.71299779, 0.77902779, 0.7170738 , 0.77206376, 0.45016676]]),\n",
       "        0,\n",
       "        0,\n",
       "        array([[0.39891124, 0.50250242, 0.57444326, 0.7957598 , 0.71299779,\n",
       "                0.77902779, 0.7170738 , 0.77206376, 0.45016676, 0.5914578 ]]),\n",
       "        False),\n",
       "       (array([[0.39891124, 0.50250242, 0.57444326, 0.7957598 , 0.71299779,\n",
       "                0.77902779, 0.7170738 , 0.77206376, 0.45016676, 0.5914578 ]]),\n",
       "        0,\n",
       "        0,\n",
       "        array([[0.50250242, 0.57444326, 0.7957598 , 0.71299779, 0.77902779,\n",
       "                0.7170738 , 0.77206376, 0.45016676, 0.5914578 , 0.80218534]]),\n",
       "        False),\n",
       "       (array([[0.50250242, 0.57444326, 0.7957598 , 0.71299779, 0.77902779,\n",
       "                0.7170738 , 0.77206376, 0.45016676, 0.5914578 , 0.80218534]]),\n",
       "        2,\n",
       "        9.75,\n",
       "        array([[0.57444326, 0.7957598 , 0.71299779, 0.77902779, 0.7170738 ,\n",
       "                0.77206376, 0.45016676, 0.5914578 , 0.80218534, 0.44769043]]),\n",
       "        False),\n",
       "       (array([[0.57444326, 0.7957598 , 0.71299779, 0.77902779, 0.7170738 ,\n",
       "                0.77206376, 0.45016676, 0.5914578 , 0.80218534, 0.44769043]]),\n",
       "        1,\n",
       "        0,\n",
       "        array([[0.7957598 , 0.71299779, 0.77902779, 0.7170738 , 0.77206376,\n",
       "                0.45016676, 0.5914578 , 0.80218534, 0.44769043, 0.53991579]]),\n",
       "        False)],\n",
       "      maxlen=2000)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trader.memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trader.batch_train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "31"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "106"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(trader.memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[0.82778248, 0.39891124, 0.50250242, 0.57444326, 0.7957598 ,\n",
       "         0.71299779, 0.77902779, 0.7170738 , 0.77206376, 0.45016676]]),\n",
       " 0,\n",
       " 0,\n",
       " array([[0.39891124, 0.50250242, 0.57444326, 0.7957598 , 0.71299779,\n",
       "         0.77902779, 0.7170738 , 0.77206376, 0.45016676, 0.5914578 ]]),\n",
       " False)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trader.memory[52]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      146.202915\n",
       "1      145.497950\n",
       "2      144.924388\n",
       "3      145.094980\n",
       "4      145.688369\n",
       "          ...    \n",
       "881    325.840001\n",
       "882    325.112858\n",
       "883    324.418097\n",
       "884    323.774286\n",
       "885    323.648096\n",
       "Name: SMA_21, Length: 886, dtype: float64"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.5       , 0.5       , 0.5       , 0.5       , 0.5       ,\n",
       "        0.5       , 0.5       , 0.5       , 0.5       , 0.33071239]])"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 115ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 99.85104, 104.43879, 106.46851]], dtype=float32)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trader.model.predict(state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.7957598 , 0.71299779, 0.77902779, 0.7170738 , 0.77206376,\n",
       "        0.45016676, 0.5914578 , 0.80218534, 0.44769043, 0.53991579]])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trader.trade(state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "deque([(array([[0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5]]),\n",
       "        1,\n",
       "        0,\n",
       "        array([[0.5       , 0.5       , 0.5       , 0.5       , 0.5       ,\n",
       "                0.5       , 0.5       , 0.5       , 0.5       , 0.79248934]]),\n",
       "        False),\n",
       "       (array([[0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5]]),\n",
       "        2,\n",
       "        0,\n",
       "        array([[0.5       , 0.5       , 0.5       , 0.5       , 0.5       ,\n",
       "                0.5       , 0.5       , 0.5       , 0.5       , 0.79248934]]),\n",
       "        False),\n",
       "       (array([[0.5       , 0.5       , 0.5       , 0.5       , 0.5       ,\n",
       "                0.5       , 0.5       , 0.5       , 0.5       , 0.79248934]]),\n",
       "        1,\n",
       "        0,\n",
       "        array([[0.5       , 0.5       , 0.5       , 0.5       , 0.5       ,\n",
       "                0.5       , 0.5       , 0.5       , 0.79248934, 0.45511914]]),\n",
       "        False),\n",
       "       (array([[0.5       , 0.5       , 0.5       , 0.5       , 0.5       ,\n",
       "                0.5       , 0.5       , 0.5       , 0.79248934, 0.45511914]]),\n",
       "        0,\n",
       "        0,\n",
       "        array([[0.5       , 0.5       , 0.5       , 0.5       , 0.5       ,\n",
       "                0.5       , 0.5       , 0.79248934, 0.45511914, 0.69211224]]),\n",
       "        False),\n",
       "       (array([[0.5       , 0.5       , 0.5       , 0.5       , 0.5       ,\n",
       "                0.5       , 0.5       , 0.79248934, 0.45511914, 0.69211224]]),\n",
       "        2,\n",
       "        0.6300048828125,\n",
       "        array([[0.5       , 0.5       , 0.5       , 0.5       , 0.5       ,\n",
       "                0.5       , 0.79248934, 0.45511914, 0.69211224, 0.3208213 ]]),\n",
       "        False),\n",
       "       (array([[0.5       , 0.5       , 0.5       , 0.5       , 0.5       ,\n",
       "                0.5       , 0.79248934, 0.45511914, 0.69211224, 0.3208213 ]]),\n",
       "        1,\n",
       "        0,\n",
       "        array([[0.5       , 0.5       , 0.5       , 0.5       , 0.5       ,\n",
       "                0.79248934, 0.45511914, 0.69211224, 0.3208213 , 0.5       ]]),\n",
       "        False),\n",
       "       (array([[0.5       , 0.5       , 0.5       , 0.5       , 0.5       ,\n",
       "                0.79248934, 0.45511914, 0.69211224, 0.3208213 , 0.5       ]]),\n",
       "        2,\n",
       "        0.0,\n",
       "        array([[0.5       , 0.5       , 0.5       , 0.5       , 0.79248934,\n",
       "                0.45511914, 0.69211224, 0.3208213 , 0.5       , 0.65475332]]),\n",
       "        False),\n",
       "       (array([[0.5       , 0.5       , 0.5       , 0.5       , 0.79248934,\n",
       "                0.45511914, 0.69211224, 0.3208213 , 0.5       , 0.65475332]]),\n",
       "        1,\n",
       "        0,\n",
       "        array([[0.5       , 0.5       , 0.5       , 0.79248934, 0.45511914,\n",
       "                0.69211224, 0.3208213 , 0.5       , 0.65475332, 0.36123513]]),\n",
       "        False),\n",
       "       (array([[0.5       , 0.5       , 0.5       , 0.79248934, 0.45511914,\n",
       "                0.69211224, 0.3208213 , 0.5       , 0.65475332, 0.36123513]]),\n",
       "        2,\n",
       "        0,\n",
       "        array([[0.5       , 0.5       , 0.79248934, 0.45511914, 0.69211224,\n",
       "                0.3208213 , 0.5       , 0.65475332, 0.36123513, 0.62714877]]),\n",
       "        False),\n",
       "       (array([[0.5       , 0.5       , 0.79248934, 0.45511914, 0.69211224,\n",
       "                0.3208213 , 0.5       , 0.65475332, 0.36123513, 0.62714877]]),\n",
       "        1,\n",
       "        0,\n",
       "        array([[0.5       , 0.79248934, 0.45511914, 0.69211224, 0.3208213 ,\n",
       "                0.5       , 0.65475332, 0.36123513, 0.62714877, 0.31002487]]),\n",
       "        False),\n",
       "       (array([[0.5       , 0.79248934, 0.45511914, 0.69211224, 0.3208213 ,\n",
       "                0.5       , 0.65475332, 0.36123513, 0.62714877, 0.31002487]]),\n",
       "        2,\n",
       "        0,\n",
       "        array([[0.79248934, 0.45511914, 0.69211224, 0.3208213 , 0.5       ,\n",
       "                0.65475332, 0.36123513, 0.62714877, 0.31002487, 0.62245933]]),\n",
       "        False),\n",
       "       (array([[0.79248934, 0.45511914, 0.69211224, 0.3208213 , 0.5       ,\n",
       "                0.65475332, 0.36123513, 0.62714877, 0.31002487, 0.62245933]]),\n",
       "        0,\n",
       "        0,\n",
       "        array([[0.45511914, 0.69211224, 0.3208213 , 0.5       , 0.65475332,\n",
       "                0.36123513, 0.62714877, 0.31002487, 0.62245933, 0.30153556]]),\n",
       "        False),\n",
       "       (array([[0.45511914, 0.69211224, 0.3208213 , 0.5       , 0.65475332,\n",
       "                0.36123513, 0.62714877, 0.31002487, 0.62245933, 0.30153556]]),\n",
       "        0,\n",
       "        0,\n",
       "        array([[0.69211224, 0.3208213 , 0.5       , 0.65475332, 0.36123513,\n",
       "                0.62714877, 0.31002487, 0.62245933, 0.30153556, 0.69635532]]),\n",
       "        False),\n",
       "       (array([[0.69211224, 0.3208213 , 0.5       , 0.65475332, 0.36123513,\n",
       "                0.62714877, 0.31002487, 0.62245933, 0.30153556, 0.69635532]]),\n",
       "        2,\n",
       "        0,\n",
       "        array([[0.3208213 , 0.5       , 0.65475332, 0.36123513, 0.62714877,\n",
       "                0.31002487, 0.62245933, 0.30153556, 0.69635532, 0.35663219]]),\n",
       "        False),\n",
       "       (array([[0.3208213 , 0.5       , 0.65475332, 0.36123513, 0.62714877,\n",
       "                0.31002487, 0.62245933, 0.30153556, 0.69635532, 0.35663219]]),\n",
       "        2,\n",
       "        0,\n",
       "        array([[0.5       , 0.65475332, 0.36123513, 0.62714877, 0.31002487,\n",
       "                0.62245933, 0.30153556, 0.69635532, 0.35663219, 0.81000031]]),\n",
       "        False),\n",
       "       (array([[0.5       , 0.65475332, 0.36123513, 0.62714877, 0.31002487,\n",
       "                0.62245933, 0.30153556, 0.69635532, 0.35663219, 0.81000031]]),\n",
       "        0,\n",
       "        0,\n",
       "        array([[0.65475332, 0.36123513, 0.62714877, 0.31002487, 0.62245933,\n",
       "                0.30153556, 0.69635532, 0.35663219, 0.81000031, 0.87761124]]),\n",
       "        False),\n",
       "       (array([[0.65475332, 0.36123513, 0.62714877, 0.31002487, 0.62245933,\n",
       "                0.30153556, 0.69635532, 0.35663219, 0.81000031, 0.87761124]]),\n",
       "        1,\n",
       "        0,\n",
       "        array([[0.36123513, 0.62714877, 0.31002487, 0.62245933, 0.30153556,\n",
       "                0.69635532, 0.35663219, 0.81000031, 0.87761124, 0.440285  ]]),\n",
       "        False),\n",
       "       (array([[0.36123513, 0.62714877, 0.31002487, 0.62245933, 0.30153556,\n",
       "                0.69635532, 0.35663219, 0.81000031, 0.87761124, 0.440285  ]]),\n",
       "        2,\n",
       "        0,\n",
       "        array([[0.62714877, 0.31002487, 0.62245933, 0.30153556, 0.69635532,\n",
       "                0.35663219, 0.81000031, 0.87761124, 0.440285  , 0.41095942]]),\n",
       "        False),\n",
       "       (array([[0.62714877, 0.31002487, 0.62245933, 0.30153556, 0.69635532,\n",
       "                0.35663219, 0.81000031, 0.87761124, 0.440285  , 0.41095942]]),\n",
       "        2,\n",
       "        0,\n",
       "        array([[0.31002487, 0.62245933, 0.30153556, 0.69635532, 0.35663219,\n",
       "                0.81000031, 0.87761124, 0.440285  , 0.41095942, 0.19466187]]),\n",
       "        False),\n",
       "       (array([[0.31002487, 0.62245933, 0.30153556, 0.69635532, 0.35663219,\n",
       "                0.81000031, 0.87761124, 0.440285  , 0.41095942, 0.19466187]]),\n",
       "        0,\n",
       "        0,\n",
       "        array([[0.62245933, 0.30153556, 0.69635532, 0.35663219, 0.81000031,\n",
       "                0.87761124, 0.440285  , 0.41095942, 0.19466187, 0.4949991 ]]),\n",
       "        False),\n",
       "       (array([[0.62245933, 0.30153556, 0.69635532, 0.35663219, 0.81000031,\n",
       "                0.87761124, 0.440285  , 0.41095942, 0.19466187, 0.4949991 ]]),\n",
       "        0,\n",
       "        0,\n",
       "        array([[0.30153556, 0.69635532, 0.35663219, 0.81000031, 0.87761124,\n",
       "                0.440285  , 0.41095942, 0.19466187, 0.4949991 , 0.52248391]]),\n",
       "        False),\n",
       "       (array([[0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5]]),\n",
       "        0,\n",
       "        0,\n",
       "        array([[0.5       , 0.5       , 0.5       , 0.5       , 0.5       ,\n",
       "                0.5       , 0.5       , 0.5       , 0.5       , 0.79248934]]),\n",
       "        False),\n",
       "       (array([[0.5       , 0.5       , 0.5       , 0.5       , 0.5       ,\n",
       "                0.5       , 0.5       , 0.5       , 0.5       , 0.79248934]]),\n",
       "        0,\n",
       "        0,\n",
       "        array([[0.5       , 0.5       , 0.5       , 0.5       , 0.5       ,\n",
       "                0.5       , 0.5       , 0.5       , 0.79248934, 0.45511914]]),\n",
       "        False),\n",
       "       (array([[0.5       , 0.5       , 0.5       , 0.5       , 0.5       ,\n",
       "                0.5       , 0.5       , 0.5       , 0.79248934, 0.45511914]]),\n",
       "        0,\n",
       "        0,\n",
       "        array([[0.5       , 0.5       , 0.5       , 0.5       , 0.5       ,\n",
       "                0.5       , 0.5       , 0.79248934, 0.45511914, 0.69211224]]),\n",
       "        False),\n",
       "       (array([[0.5       , 0.5       , 0.5       , 0.5       , 0.5       ,\n",
       "                0.5       , 0.5       , 0.79248934, 0.45511914, 0.69211224]]),\n",
       "        2,\n",
       "        0,\n",
       "        array([[0.5       , 0.5       , 0.5       , 0.5       , 0.5       ,\n",
       "                0.5       , 0.79248934, 0.45511914, 0.69211224, 0.3208213 ]]),\n",
       "        False),\n",
       "       (array([[0.5       , 0.5       , 0.5       , 0.5       , 0.5       ,\n",
       "                0.5       , 0.79248934, 0.45511914, 0.69211224, 0.3208213 ]]),\n",
       "        1,\n",
       "        0,\n",
       "        array([[0.5       , 0.5       , 0.5       , 0.5       , 0.5       ,\n",
       "                0.79248934, 0.45511914, 0.69211224, 0.3208213 , 0.5       ]]),\n",
       "        False),\n",
       "       (array([[0.5       , 0.5       , 0.5       , 0.5       , 0.5       ,\n",
       "                0.79248934, 0.45511914, 0.69211224, 0.3208213 , 0.5       ]]),\n",
       "        1,\n",
       "        0,\n",
       "        array([[0.5       , 0.5       , 0.5       , 0.5       , 0.79248934,\n",
       "                0.45511914, 0.69211224, 0.3208213 , 0.5       , 0.65475332]]),\n",
       "        False),\n",
       "       (array([[0.5       , 0.5       , 0.5       , 0.5       , 0.79248934,\n",
       "                0.45511914, 0.69211224, 0.3208213 , 0.5       , 0.65475332]]),\n",
       "        0,\n",
       "        0,\n",
       "        array([[0.5       , 0.5       , 0.5       , 0.79248934, 0.45511914,\n",
       "                0.69211224, 0.3208213 , 0.5       , 0.65475332, 0.36123513]]),\n",
       "        False),\n",
       "       (array([[0.5       , 0.5       , 0.5       , 0.79248934, 0.45511914,\n",
       "                0.69211224, 0.3208213 , 0.5       , 0.65475332, 0.36123513]]),\n",
       "        1,\n",
       "        0,\n",
       "        array([[0.5       , 0.5       , 0.79248934, 0.45511914, 0.69211224,\n",
       "                0.3208213 , 0.5       , 0.65475332, 0.36123513, 0.62714877]]),\n",
       "        False),\n",
       "       (array([[0.5       , 0.5       , 0.79248934, 0.45511914, 0.69211224,\n",
       "                0.3208213 , 0.5       , 0.65475332, 0.36123513, 0.62714877]]),\n",
       "        2,\n",
       "        0.589996337890625,\n",
       "        array([[0.5       , 0.79248934, 0.45511914, 0.69211224, 0.3208213 ,\n",
       "                0.5       , 0.65475332, 0.36123513, 0.62714877, 0.31002487]]),\n",
       "        False),\n",
       "       (array([[0.5       , 0.79248934, 0.45511914, 0.69211224, 0.3208213 ,\n",
       "                0.5       , 0.65475332, 0.36123513, 0.62714877, 0.31002487]]),\n",
       "        1,\n",
       "        0,\n",
       "        array([[0.79248934, 0.45511914, 0.69211224, 0.3208213 , 0.5       ,\n",
       "                0.65475332, 0.36123513, 0.62714877, 0.31002487, 0.62245933]]),\n",
       "        False),\n",
       "       (array([[0.79248934, 0.45511914, 0.69211224, 0.3208213 , 0.5       ,\n",
       "                0.65475332, 0.36123513, 0.62714877, 0.31002487, 0.62245933]]),\n",
       "        1,\n",
       "        0,\n",
       "        array([[0.45511914, 0.69211224, 0.3208213 , 0.5       , 0.65475332,\n",
       "                0.36123513, 0.62714877, 0.31002487, 0.62245933, 0.30153556]]),\n",
       "        False),\n",
       "       (array([[0.45511914, 0.69211224, 0.3208213 , 0.5       , 0.65475332,\n",
       "                0.36123513, 0.62714877, 0.31002487, 0.62245933, 0.30153556]]),\n",
       "        1,\n",
       "        0,\n",
       "        array([[0.69211224, 0.3208213 , 0.5       , 0.65475332, 0.36123513,\n",
       "                0.62714877, 0.31002487, 0.62245933, 0.30153556, 0.69635532]]),\n",
       "        False),\n",
       "       (array([[0.69211224, 0.3208213 , 0.5       , 0.65475332, 0.36123513,\n",
       "                0.62714877, 0.31002487, 0.62245933, 0.30153556, 0.69635532]]),\n",
       "        1,\n",
       "        0,\n",
       "        array([[0.3208213 , 0.5       , 0.65475332, 0.36123513, 0.62714877,\n",
       "                0.31002487, 0.62245933, 0.30153556, 0.69635532, 0.35663219]]),\n",
       "        False),\n",
       "       (array([[0.3208213 , 0.5       , 0.65475332, 0.36123513, 0.62714877,\n",
       "                0.31002487, 0.62245933, 0.30153556, 0.69635532, 0.35663219]]),\n",
       "        0,\n",
       "        0,\n",
       "        array([[0.5       , 0.65475332, 0.36123513, 0.62714877, 0.31002487,\n",
       "                0.62245933, 0.30153556, 0.69635532, 0.35663219, 0.81000031]]),\n",
       "        False),\n",
       "       (array([[0.5       , 0.65475332, 0.36123513, 0.62714877, 0.31002487,\n",
       "                0.62245933, 0.30153556, 0.69635532, 0.35663219, 0.81000031]]),\n",
       "        0,\n",
       "        0,\n",
       "        array([[0.65475332, 0.36123513, 0.62714877, 0.31002487, 0.62245933,\n",
       "                0.30153556, 0.69635532, 0.35663219, 0.81000031, 0.87761124]]),\n",
       "        False),\n",
       "       (array([[0.65475332, 0.36123513, 0.62714877, 0.31002487, 0.62245933,\n",
       "                0.30153556, 0.69635532, 0.35663219, 0.81000031, 0.87761124]]),\n",
       "        0,\n",
       "        0,\n",
       "        array([[0.36123513, 0.62714877, 0.31002487, 0.62245933, 0.30153556,\n",
       "                0.69635532, 0.35663219, 0.81000031, 0.87761124, 0.440285  ]]),\n",
       "        False),\n",
       "       (array([[0.36123513, 0.62714877, 0.31002487, 0.62245933, 0.30153556,\n",
       "                0.69635532, 0.35663219, 0.81000031, 0.87761124, 0.440285  ]]),\n",
       "        0,\n",
       "        0,\n",
       "        array([[0.62714877, 0.31002487, 0.62245933, 0.30153556, 0.69635532,\n",
       "                0.35663219, 0.81000031, 0.87761124, 0.440285  , 0.41095942]]),\n",
       "        False),\n",
       "       (array([[0.62714877, 0.31002487, 0.62245933, 0.30153556, 0.69635532,\n",
       "                0.35663219, 0.81000031, 0.87761124, 0.440285  , 0.41095942]]),\n",
       "        2,\n",
       "        2.5099945068359375,\n",
       "        array([[0.31002487, 0.62245933, 0.30153556, 0.69635532, 0.35663219,\n",
       "                0.81000031, 0.87761124, 0.440285  , 0.41095942, 0.19466187]]),\n",
       "        False),\n",
       "       (array([[0.31002487, 0.62245933, 0.30153556, 0.69635532, 0.35663219,\n",
       "                0.81000031, 0.87761124, 0.440285  , 0.41095942, 0.19466187]]),\n",
       "        1,\n",
       "        0,\n",
       "        array([[0.62245933, 0.30153556, 0.69635532, 0.35663219, 0.81000031,\n",
       "                0.87761124, 0.440285  , 0.41095942, 0.19466187, 0.4949991 ]]),\n",
       "        False),\n",
       "       (array([[0.62245933, 0.30153556, 0.69635532, 0.35663219, 0.81000031,\n",
       "                0.87761124, 0.440285  , 0.41095942, 0.19466187, 0.4949991 ]]),\n",
       "        1,\n",
       "        0,\n",
       "        array([[0.30153556, 0.69635532, 0.35663219, 0.81000031, 0.87761124,\n",
       "                0.440285  , 0.41095942, 0.19466187, 0.4949991 , 0.52248391]]),\n",
       "        False),\n",
       "       (array([[0.30153556, 0.69635532, 0.35663219, 0.81000031, 0.87761124,\n",
       "                0.440285  , 0.41095942, 0.19466187, 0.4949991 , 0.52248391]]),\n",
       "        1,\n",
       "        0,\n",
       "        array([[0.69635532, 0.35663219, 0.81000031, 0.87761124, 0.440285  ,\n",
       "                0.41095942, 0.19466187, 0.4949991 , 0.52248391, 0.53743212]]),\n",
       "        False),\n",
       "       (array([[0.69635532, 0.35663219, 0.81000031, 0.87761124, 0.440285  ,\n",
       "                0.41095942, 0.19466187, 0.4949991 , 0.52248391, 0.53743212]]),\n",
       "        1,\n",
       "        0,\n",
       "        array([[0.35663219, 0.81000031, 0.87761124, 0.440285  , 0.41095942,\n",
       "                0.19466187, 0.4949991 , 0.52248391, 0.53743212, 0.82778248]]),\n",
       "        False),\n",
       "       (array([[0.35663219, 0.81000031, 0.87761124, 0.440285  , 0.41095942,\n",
       "                0.19466187, 0.4949991 , 0.52248391, 0.53743212, 0.82778248]]),\n",
       "        0,\n",
       "        0,\n",
       "        array([[0.81000031, 0.87761124, 0.440285  , 0.41095942, 0.19466187,\n",
       "                0.4949991 , 0.52248391, 0.53743212, 0.82778248, 0.39891124]]),\n",
       "        False),\n",
       "       (array([[0.81000031, 0.87761124, 0.440285  , 0.41095942, 0.19466187,\n",
       "                0.4949991 , 0.52248391, 0.53743212, 0.82778248, 0.39891124]]),\n",
       "        2,\n",
       "        2.399993896484375,\n",
       "        array([[0.87761124, 0.440285  , 0.41095942, 0.19466187, 0.4949991 ,\n",
       "                0.52248391, 0.53743212, 0.82778248, 0.39891124, 0.50250242]]),\n",
       "        False),\n",
       "       (array([[0.87761124, 0.440285  , 0.41095942, 0.19466187, 0.4949991 ,\n",
       "                0.52248391, 0.53743212, 0.82778248, 0.39891124, 0.50250242]]),\n",
       "        1,\n",
       "        0,\n",
       "        array([[0.440285  , 0.41095942, 0.19466187, 0.4949991 , 0.52248391,\n",
       "                0.53743212, 0.82778248, 0.39891124, 0.50250242, 0.57444326]]),\n",
       "        False),\n",
       "       (array([[0.440285  , 0.41095942, 0.19466187, 0.4949991 , 0.52248391,\n",
       "                0.53743212, 0.82778248, 0.39891124, 0.50250242, 0.57444326]]),\n",
       "        1,\n",
       "        0,\n",
       "        array([[0.41095942, 0.19466187, 0.4949991 , 0.52248391, 0.53743212,\n",
       "                0.82778248, 0.39891124, 0.50250242, 0.57444326, 0.7957598 ]]),\n",
       "        False),\n",
       "       (array([[0.41095942, 0.19466187, 0.4949991 , 0.52248391, 0.53743212,\n",
       "                0.82778248, 0.39891124, 0.50250242, 0.57444326, 0.7957598 ]]),\n",
       "        2,\n",
       "        4.350006103515625,\n",
       "        array([[0.19466187, 0.4949991 , 0.52248391, 0.53743212, 0.82778248,\n",
       "                0.39891124, 0.50250242, 0.57444326, 0.7957598 , 0.71299779]]),\n",
       "        False),\n",
       "       (array([[0.19466187, 0.4949991 , 0.52248391, 0.53743212, 0.82778248,\n",
       "                0.39891124, 0.50250242, 0.57444326, 0.7957598 , 0.71299779]]),\n",
       "        2,\n",
       "        4.7599945068359375,\n",
       "        array([[0.4949991 , 0.52248391, 0.53743212, 0.82778248, 0.39891124,\n",
       "                0.50250242, 0.57444326, 0.7957598 , 0.71299779, 0.77902779]]),\n",
       "        False),\n",
       "       (array([[0.4949991 , 0.52248391, 0.53743212, 0.82778248, 0.39891124,\n",
       "                0.50250242, 0.57444326, 0.7957598 , 0.71299779, 0.77902779]]),\n",
       "        2,\n",
       "        6.8600006103515625,\n",
       "        array([[0.52248391, 0.53743212, 0.82778248, 0.39891124, 0.50250242,\n",
       "                0.57444326, 0.7957598 , 0.71299779, 0.77902779, 0.7170738 ]]),\n",
       "        False),\n",
       "       (array([[0.52248391, 0.53743212, 0.82778248, 0.39891124, 0.50250242,\n",
       "                0.57444326, 0.7957598 , 0.71299779, 0.77902779, 0.7170738 ]]),\n",
       "        1,\n",
       "        0,\n",
       "        array([[0.53743212, 0.82778248, 0.39891124, 0.50250242, 0.57444326,\n",
       "                0.7957598 , 0.71299779, 0.77902779, 0.7170738 , 0.77206376]]),\n",
       "        False),\n",
       "       (array([[0.53743212, 0.82778248, 0.39891124, 0.50250242, 0.57444326,\n",
       "                0.7957598 , 0.71299779, 0.77902779, 0.7170738 , 0.77206376]]),\n",
       "        0,\n",
       "        0,\n",
       "        array([[0.82778248, 0.39891124, 0.50250242, 0.57444326, 0.7957598 ,\n",
       "                0.71299779, 0.77902779, 0.7170738 , 0.77206376, 0.45016676]]),\n",
       "        False),\n",
       "       (array([[0.82778248, 0.39891124, 0.50250242, 0.57444326, 0.7957598 ,\n",
       "                0.71299779, 0.77902779, 0.7170738 , 0.77206376, 0.45016676]]),\n",
       "        0,\n",
       "        0,\n",
       "        array([[0.39891124, 0.50250242, 0.57444326, 0.7957598 , 0.71299779,\n",
       "                0.77902779, 0.7170738 , 0.77206376, 0.45016676, 0.5914578 ]]),\n",
       "        False),\n",
       "       (array([[0.39891124, 0.50250242, 0.57444326, 0.7957598 , 0.71299779,\n",
       "                0.77902779, 0.7170738 , 0.77206376, 0.45016676, 0.5914578 ]]),\n",
       "        0,\n",
       "        0,\n",
       "        array([[0.50250242, 0.57444326, 0.7957598 , 0.71299779, 0.77902779,\n",
       "                0.7170738 , 0.77206376, 0.45016676, 0.5914578 , 0.80218534]]),\n",
       "        False),\n",
       "       (array([[0.50250242, 0.57444326, 0.7957598 , 0.71299779, 0.77902779,\n",
       "                0.7170738 , 0.77206376, 0.45016676, 0.5914578 , 0.80218534]]),\n",
       "        2,\n",
       "        9.75,\n",
       "        array([[0.57444326, 0.7957598 , 0.71299779, 0.77902779, 0.7170738 ,\n",
       "                0.77206376, 0.45016676, 0.5914578 , 0.80218534, 0.44769043]]),\n",
       "        False),\n",
       "       (array([[0.57444326, 0.7957598 , 0.71299779, 0.77902779, 0.7170738 ,\n",
       "                0.77206376, 0.45016676, 0.5914578 , 0.80218534, 0.44769043]]),\n",
       "        1,\n",
       "        0,\n",
       "        array([[0.7957598 , 0.71299779, 0.77902779, 0.7170738 , 0.77206376,\n",
       "                0.45016676, 0.5914578 , 0.80218534, 0.44769043, 0.53991579]]),\n",
       "        False)],\n",
       "      maxlen=2000)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trader.memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "deque([(array([[0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5]]),\n",
       "        1,\n",
       "        0,\n",
       "        array([[0.5       , 0.5       , 0.5       , 0.5       , 0.5       ,\n",
       "                0.5       , 0.5       , 0.5       , 0.5       , 0.79248934]]),\n",
       "        False),\n",
       "       (array([[0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5]]),\n",
       "        2,\n",
       "        0,\n",
       "        array([[0.5       , 0.5       , 0.5       , 0.5       , 0.5       ,\n",
       "                0.5       , 0.5       , 0.5       , 0.5       , 0.79248934]]),\n",
       "        False),\n",
       "       (array([[0.5       , 0.5       , 0.5       , 0.5       , 0.5       ,\n",
       "                0.5       , 0.5       , 0.5       , 0.5       , 0.79248934]]),\n",
       "        1,\n",
       "        0,\n",
       "        array([[0.5       , 0.5       , 0.5       , 0.5       , 0.5       ,\n",
       "                0.5       , 0.5       , 0.5       , 0.79248934, 0.45511914]]),\n",
       "        False),\n",
       "       (array([[0.5       , 0.5       , 0.5       , 0.5       , 0.5       ,\n",
       "                0.5       , 0.5       , 0.5       , 0.79248934, 0.45511914]]),\n",
       "        0,\n",
       "        0,\n",
       "        array([[0.5       , 0.5       , 0.5       , 0.5       , 0.5       ,\n",
       "                0.5       , 0.5       , 0.79248934, 0.45511914, 0.69211224]]),\n",
       "        False),\n",
       "       (array([[0.5       , 0.5       , 0.5       , 0.5       , 0.5       ,\n",
       "                0.5       , 0.5       , 0.79248934, 0.45511914, 0.69211224]]),\n",
       "        2,\n",
       "        0.6300048828125,\n",
       "        array([[0.5       , 0.5       , 0.5       , 0.5       , 0.5       ,\n",
       "                0.5       , 0.79248934, 0.45511914, 0.69211224, 0.3208213 ]]),\n",
       "        False),\n",
       "       (array([[0.5       , 0.5       , 0.5       , 0.5       , 0.5       ,\n",
       "                0.5       , 0.79248934, 0.45511914, 0.69211224, 0.3208213 ]]),\n",
       "        1,\n",
       "        0,\n",
       "        array([[0.5       , 0.5       , 0.5       , 0.5       , 0.5       ,\n",
       "                0.79248934, 0.45511914, 0.69211224, 0.3208213 , 0.5       ]]),\n",
       "        False),\n",
       "       (array([[0.5       , 0.5       , 0.5       , 0.5       , 0.5       ,\n",
       "                0.79248934, 0.45511914, 0.69211224, 0.3208213 , 0.5       ]]),\n",
       "        2,\n",
       "        0.0,\n",
       "        array([[0.5       , 0.5       , 0.5       , 0.5       , 0.79248934,\n",
       "                0.45511914, 0.69211224, 0.3208213 , 0.5       , 0.65475332]]),\n",
       "        False),\n",
       "       (array([[0.5       , 0.5       , 0.5       , 0.5       , 0.79248934,\n",
       "                0.45511914, 0.69211224, 0.3208213 , 0.5       , 0.65475332]]),\n",
       "        1,\n",
       "        0,\n",
       "        array([[0.5       , 0.5       , 0.5       , 0.79248934, 0.45511914,\n",
       "                0.69211224, 0.3208213 , 0.5       , 0.65475332, 0.36123513]]),\n",
       "        False),\n",
       "       (array([[0.5       , 0.5       , 0.5       , 0.79248934, 0.45511914,\n",
       "                0.69211224, 0.3208213 , 0.5       , 0.65475332, 0.36123513]]),\n",
       "        2,\n",
       "        0,\n",
       "        array([[0.5       , 0.5       , 0.79248934, 0.45511914, 0.69211224,\n",
       "                0.3208213 , 0.5       , 0.65475332, 0.36123513, 0.62714877]]),\n",
       "        False),\n",
       "       (array([[0.5       , 0.5       , 0.79248934, 0.45511914, 0.69211224,\n",
       "                0.3208213 , 0.5       , 0.65475332, 0.36123513, 0.62714877]]),\n",
       "        1,\n",
       "        0,\n",
       "        array([[0.5       , 0.79248934, 0.45511914, 0.69211224, 0.3208213 ,\n",
       "                0.5       , 0.65475332, 0.36123513, 0.62714877, 0.31002487]]),\n",
       "        False),\n",
       "       (array([[0.5       , 0.79248934, 0.45511914, 0.69211224, 0.3208213 ,\n",
       "                0.5       , 0.65475332, 0.36123513, 0.62714877, 0.31002487]]),\n",
       "        2,\n",
       "        0,\n",
       "        array([[0.79248934, 0.45511914, 0.69211224, 0.3208213 , 0.5       ,\n",
       "                0.65475332, 0.36123513, 0.62714877, 0.31002487, 0.62245933]]),\n",
       "        False),\n",
       "       (array([[0.79248934, 0.45511914, 0.69211224, 0.3208213 , 0.5       ,\n",
       "                0.65475332, 0.36123513, 0.62714877, 0.31002487, 0.62245933]]),\n",
       "        0,\n",
       "        0,\n",
       "        array([[0.45511914, 0.69211224, 0.3208213 , 0.5       , 0.65475332,\n",
       "                0.36123513, 0.62714877, 0.31002487, 0.62245933, 0.30153556]]),\n",
       "        False),\n",
       "       (array([[0.45511914, 0.69211224, 0.3208213 , 0.5       , 0.65475332,\n",
       "                0.36123513, 0.62714877, 0.31002487, 0.62245933, 0.30153556]]),\n",
       "        0,\n",
       "        0,\n",
       "        array([[0.69211224, 0.3208213 , 0.5       , 0.65475332, 0.36123513,\n",
       "                0.62714877, 0.31002487, 0.62245933, 0.30153556, 0.69635532]]),\n",
       "        False),\n",
       "       (array([[0.69211224, 0.3208213 , 0.5       , 0.65475332, 0.36123513,\n",
       "                0.62714877, 0.31002487, 0.62245933, 0.30153556, 0.69635532]]),\n",
       "        2,\n",
       "        0,\n",
       "        array([[0.3208213 , 0.5       , 0.65475332, 0.36123513, 0.62714877,\n",
       "                0.31002487, 0.62245933, 0.30153556, 0.69635532, 0.35663219]]),\n",
       "        False),\n",
       "       (array([[0.3208213 , 0.5       , 0.65475332, 0.36123513, 0.62714877,\n",
       "                0.31002487, 0.62245933, 0.30153556, 0.69635532, 0.35663219]]),\n",
       "        2,\n",
       "        0,\n",
       "        array([[0.5       , 0.65475332, 0.36123513, 0.62714877, 0.31002487,\n",
       "                0.62245933, 0.30153556, 0.69635532, 0.35663219, 0.81000031]]),\n",
       "        False),\n",
       "       (array([[0.5       , 0.65475332, 0.36123513, 0.62714877, 0.31002487,\n",
       "                0.62245933, 0.30153556, 0.69635532, 0.35663219, 0.81000031]]),\n",
       "        0,\n",
       "        0,\n",
       "        array([[0.65475332, 0.36123513, 0.62714877, 0.31002487, 0.62245933,\n",
       "                0.30153556, 0.69635532, 0.35663219, 0.81000031, 0.87761124]]),\n",
       "        False),\n",
       "       (array([[0.65475332, 0.36123513, 0.62714877, 0.31002487, 0.62245933,\n",
       "                0.30153556, 0.69635532, 0.35663219, 0.81000031, 0.87761124]]),\n",
       "        1,\n",
       "        0,\n",
       "        array([[0.36123513, 0.62714877, 0.31002487, 0.62245933, 0.30153556,\n",
       "                0.69635532, 0.35663219, 0.81000031, 0.87761124, 0.440285  ]]),\n",
       "        False),\n",
       "       (array([[0.36123513, 0.62714877, 0.31002487, 0.62245933, 0.30153556,\n",
       "                0.69635532, 0.35663219, 0.81000031, 0.87761124, 0.440285  ]]),\n",
       "        2,\n",
       "        0,\n",
       "        array([[0.62714877, 0.31002487, 0.62245933, 0.30153556, 0.69635532,\n",
       "                0.35663219, 0.81000031, 0.87761124, 0.440285  , 0.41095942]]),\n",
       "        False),\n",
       "       (array([[0.62714877, 0.31002487, 0.62245933, 0.30153556, 0.69635532,\n",
       "                0.35663219, 0.81000031, 0.87761124, 0.440285  , 0.41095942]]),\n",
       "        2,\n",
       "        0,\n",
       "        array([[0.31002487, 0.62245933, 0.30153556, 0.69635532, 0.35663219,\n",
       "                0.81000031, 0.87761124, 0.440285  , 0.41095942, 0.19466187]]),\n",
       "        False),\n",
       "       (array([[0.31002487, 0.62245933, 0.30153556, 0.69635532, 0.35663219,\n",
       "                0.81000031, 0.87761124, 0.440285  , 0.41095942, 0.19466187]]),\n",
       "        0,\n",
       "        0,\n",
       "        array([[0.62245933, 0.30153556, 0.69635532, 0.35663219, 0.81000031,\n",
       "                0.87761124, 0.440285  , 0.41095942, 0.19466187, 0.4949991 ]]),\n",
       "        False),\n",
       "       (array([[0.62245933, 0.30153556, 0.69635532, 0.35663219, 0.81000031,\n",
       "                0.87761124, 0.440285  , 0.41095942, 0.19466187, 0.4949991 ]]),\n",
       "        0,\n",
       "        0,\n",
       "        array([[0.30153556, 0.69635532, 0.35663219, 0.81000031, 0.87761124,\n",
       "                0.440285  , 0.41095942, 0.19466187, 0.4949991 , 0.52248391]]),\n",
       "        False)],\n",
       "      maxlen=2000)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory = trader.memory\n",
    "memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory[1][2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterrate in momory, we do not want to randolmy select data as we are dealing with \n",
    "#    time constraint data. We will always sample from the end of memory size of bath\n",
    "for i in range(len(memory) - batch_size + 1, len(memory)):\n",
    "    # insert data from memory to batch      \n",
    "  batch.append(memory[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "31"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.71299779, 0.77902779, 0.7170738 , 0.77206376, 0.45016676,\n",
       "        0.5914578 , 0.80218534, 0.44769043, 0.53991579, 0.57444326]])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = 35\n",
    "next_state = state_creator(data=data, timestep=(t + 1), window_size=(window_size + 1))\n",
    "next_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 1s/step\n",
      "1/1 [==============================] - 0s 163ms/step\n",
      "1/1 [==============================] - 0s 60ms/step\n",
      "1/1 [==============================] - 0s 59ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 59ms/step\n",
      "1/1 [==============================] - 0s 66ms/step\n",
      "1/1 [==============================] - 0s 76ms/step\n",
      "1/1 [==============================] - 0s 254ms/step\n",
      "1/1 [==============================] - 0s 73ms/step\n",
      "1/1 [==============================] - 0s 79ms/step\n",
      "1/1 [==============================] - 0s 61ms/step\n",
      "1/1 [==============================] - 0s 58ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 51ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 58ms/step\n",
      "1/1 [==============================] - 0s 59ms/step\n",
      "1/1 [==============================] - 0s 58ms/step\n",
      "1/1 [==============================] - 0s 79ms/step\n",
      "1/1 [==============================] - 0s 60ms/step\n",
      "1/1 [==============================] - 0s 69ms/step\n",
      "1/1 [==============================] - 0s 71ms/step\n",
      "1/1 [==============================] - 0s 69ms/step\n",
      "1/1 [==============================] - 0s 56ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 72ms/step\n",
      "1/1 [==============================] - 0s 53ms/step\n",
      "1/1 [==============================] - 0s 61ms/step\n",
      "1/1 [==============================] - 0s 65ms/step\n",
      "1/1 [==============================] - 0s 63ms/step\n",
      "1/1 [==============================] - 0s 63ms/step\n",
      "1/1 [==============================] - 0s 57ms/step\n",
      "1/1 [==============================] - 0s 70ms/step\n",
      "1/1 [==============================] - 0s 71ms/step\n",
      "1/1 [==============================] - 0s 62ms/step\n",
      "1/1 [==============================] - 0s 66ms/step\n",
      "1/1 [==============================] - 0s 57ms/step\n",
      "1/1 [==============================] - 0s 60ms/step\n",
      "1/1 [==============================] - 0s 53ms/step\n",
      "1/1 [==============================] - 0s 74ms/step\n",
      "1/1 [==============================] - 0s 74ms/step\n",
      "1/1 [==============================] - 0s 65ms/step\n",
      "1/1 [==============================] - 0s 67ms/step\n",
      "1/1 [==============================] - 0s 66ms/step\n",
      "1/1 [==============================] - 0s 66ms/step\n",
      "1/1 [==============================] - 0s 76ms/step\n",
      "1/1 [==============================] - 0s 67ms/step\n",
      "1/1 [==============================] - 0s 63ms/step\n",
      "1/1 [==============================] - 0s 63ms/step\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "1/1 [==============================] - 0s 65ms/step\n",
      "1/1 [==============================] - 0s 62ms/step\n",
      "1/1 [==============================] - 0s 69ms/step\n",
      "1/1 [==============================] - 0s 60ms/step\n",
      "1/1 [==============================] - 0s 62ms/step\n",
      "1/1 [==============================] - 0s 51ms/step\n",
      "1/1 [==============================] - 0s 63ms/step\n",
      "1/1 [==============================] - 0s 62ms/step\n",
      "1/1 [==============================] - 0s 63ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 63ms/step\n"
     ]
    }
   ],
   "source": [
    "# Iterate trought batch of data and train the model for each sample from batch\n",
    "# Order of variables in for loop is important\n",
    "for state, action, reward, next_state, done in batch:\n",
    "    # Reward if agent is in terminal state\n",
    "    reward = reward\n",
    "    # Check that agent is not in terminal state\n",
    "    # If not in terminal state calculate reward for actions that could be played\n",
    "    if not done:\n",
    "    # Discounted total reward:\n",
    "        reward = reward + trader.gamma * np.amax(trader.model.predict(next_state)[0])        \n",
    "        # Target variable that is predicted by the model (action)\n",
    "    target = trader.model.predict(state)\n",
    "    target[0][action] = reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[87.92146, 90.3666 , 92.32832]], dtype=float32)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "92.32832"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target[0][2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.0500030517578125"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[87.92146 , 90.3666  ,  2.050003]], dtype=float32)"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target[0][2] = reward\n",
    "target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.62245933, 0.30153556, 0.69635532, 0.35663219, 0.81000031,\n",
       "        0.87761124, 0.440285  , 0.41095942, 0.19466187, 0.4949991 ]])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x2d869d30a30>"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trader.model.fit(state, target, epochs=1, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 32)                352       \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 64)                2112      \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 128)               8320      \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 3)                 387       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 11171 (43.64 KB)\n",
      "Trainable params: 11171 (43.64 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "trader.model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 2s 2s/step - loss: 8133.7603\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "8133.76025390625"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(state, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.53742833, 0.32960073, 0.32959736, 0.39174039, 0.57444326,\n",
       "        0.69635532, 0.52996284, 0.28699909, 0.88594793, 0.38461595]])"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'tensorflow' has no attribute 'get_collection'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Jesus\\Github\\Material_Tec\\Codigos\\RL con TensorFlow.ipynb Cell 40\u001b[0m line \u001b[0;36m1\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/Jesus/Github/Material_Tec/Codigos/RL%20con%20TensorFlow.ipynb#X64sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m model_vars \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39;49mget_collection(tf\u001b[39m.\u001b[39mGraphKeys\u001b[39m.\u001b[39mMODEL_VARIABLES)\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'tensorflow' has no attribute 'get_collection'"
     ]
    }
   ],
   "source": [
    "model_vars = tf.get_collection(tf.GraphKeys.MODEL_VARIABLES)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    \n",
    "\n",
    "    \n",
    "    # Iterate trought batch of data and train the model for each sample from batch\n",
    "    # Order of variables in for loop is important\n",
    "    for state, action, reward, next_state, done in batch:\n",
    "      # Reward if agent is in terminal state\n",
    "      reward = reward\n",
    "      # Check that agent is not in terminal state\n",
    "      # If not in terminal state calculate reward for actions that could be played\n",
    "      if not done:\n",
    "        # Discounted total reward:\n",
    "        reward = reward + self.gamma * np.amax(self.model.predict(next_state)[0])        \n",
    "      # Target variable that is predicted by the model (action)\n",
    "      target = self.model.predict(state)\n",
    "      target[0][action] = reward\n",
    "      \n",
    "      self.model.fit(state, target, epochs=1, verbose=0)\n",
    "      \n",
    "    # We will decrease epsilon parameter that is 1 as defined in __init__  so\n",
    "    #    so we can stop performing random actions at some point\n",
    "    if self.epsilon > self.epsilon_final:\n",
    "      self.epsilon *= self.epsilon_decay"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
